
## Unusual Deaths in Mexico {#dplyr}

`r Sys.Date()`: <span style="color:red">*VERY Preliminary!*</span>


```{r, echo=FALSE}
suppressWarnings({
  suppressMessages({
    library(dplyr)
    library(ggplot2)
    library(knitr)
    library(DT)
    library(webshot)
  })  
})

load(file="tidy_case_study/tidy_case_study.RData")
deaths08 <- deaths %>% filter(yod == 2008, mod != 0, dod != 0, !is.na(hod))
deaths08b <- deaths08
colnames(deaths08b) <- c("Year of Death (yod)", "Month of Death (mod)", 
                    "Day of Death (dod)", "Hour of Death (hod)", "Cause of Death (cod)")
```

### Materials {-}
This is a practice session of [dplyr](http://docs.ggplot2.org/current/) and [ggplot2](http://docs.ggplot2.org/current/) using [a case study](http://vita.had.co.nz/papers/tidy-data.html) related to [tidyr](https://www.r-bloggers.com/data-manipulation-with-tidyr/) package.

The case is about investigating the causes of death in Mexico that have unusual temporal patterns within a day.  The data of individual-level mortality in 2008 has the following pattern of deaths by hour;    


```{r, echo=FALSE, fig.cap = 'Temporal pattern of all causes of death', out.width="90%", fig.asp=.75, fig.align='center'}
include_graphics("tidy_case_study/overall.png") 
```

Do you find anything unusual or unexpected?  The figure shows several peaks within a day, indicating some increased risks of deaths in certain times of the day.  What would be generating these patterns? 

The author finds; 

> The causes of [unusual] death fall into three main groups: murder, drowning, and transportation related. Murder is more common at night, drowning in the afternoon, and transportation related deaths during commute times. The pale gray line in the background shows the temporal course across all diseases [i.e., causes] [@Wickham2014]. 


```{r, echo=FALSE, fig.cap = 'Causes of death with unusual temporal courses. Overall hourly death rate shown in grey. Causes of death with more than 350 deaths over a year.', out.width="100%", fig.asp=.75}
include_graphics("tidy_case_study/unusual-big.png") 
```


There are two datasets: `deaths` containing the timing of deaths and coded causes and `codes` containing the lookup table for the death codes.

<!--
# ```{r, echo=FALSE} 
# DT::datatable(deaths08[1:200,],
#       colnames =  c("Year of Death (yod)", "Month of Death (mod)", 
#                     "Day of Death (dod)", "Hour of Death (hod)", "Cause of Death (cod)")
# )
# ```
-->

The dataset `deaths` has over 53,000 records (rows), so we use `head()` to look at the first several rows.

```{r}
# "deaths08b" is a renamed dataset with easier-to-read column names 
head(deaths08b) 
```


The dataset `codes` has 1851 records. The table below is generated by [DT](https://rstudio.github.io/DT/) and [webshot](https://cran.r-project.org/web/packages/webshot/vignettes/intro.html) packages. 

```{r, echo=FALSE} 
DT::datatable(codes, 
              colnames = c("Cause of Death (cod)", "Disease")
              )
```

In the search box, you can type in key words like "bacteria", "nutrition", and "fever", as well as "assault" and "exposure" to see what items are in the data.  

We will reproduce this case study and get some practice with `dplyr` and `ggplot2`. 


### Arts & Crafts {-}

Let's recap key ingredients of [dplyr](http://docs.ggplot2.org/current/) and [ggplot2](http://docs.ggplot2.org/current/) from the introduction in section \@ref(intro).

The six important functions in `dplyr` are:

* `filter()`: extracts rows (e.g. observations) of a data frame. We put logical vectors in its arguments.  

* `select()`: extracts columns (e.g. variables) of a data frame. We put column names in its arguments. 

* `arrange()`: orders rows of a data frame. We put column names in its arguments. 

* `summarise()`: collapses a data frame into summary statistics. We put **summary functions**  (e.g. statistics functions) using column names in its arguments.     

* `mutate()`: creates new variables and adds them to the existing columns. We put  **window functions** (e.g. transforming operations) using column names in its arguments.  

* `group_by()`: assigns rows into groups in a data frame. We put column names in its arguments.  
We use piping operator `%>%` (read as *then*) to translate a sentence of sequential instructions. For example, take dataset `deaths08`, `%>%` (*then*) group the data by month of death, and `%>%` (*then*) summarise the grouped data for the number of records/observations.   

```{r} 
deaths08 %>% 
  group_by(mod) %>%   # mod: month of death
  summarise( nobs = n() )  # n(): a dplyr funciton to count rows 
```



`ggplot2` graphics consist of three components: 

* **data**: a data frame e.g., the first argument in `ggplot(data, ...)`.    

* **aes**:  specifications for x-y variables, as well as variables to differentiate **geom** objects by color , shape, or size. e.g., `aes(x = var_x, y = var_y, shape = var_z)` 

* **geom**: geometric objects such as points, lines, bars, etc. e.g., `geom_point()`,  `geom_line()`,  `geom_histogram()`  
 

We specify **data** and **aes** in `ggplot()` and then add **geom** objects followed by `+` symbol (read as *add a layer of*);  e.g., `ggplot(data = dataset, mapping = aes(x = ...)) + geom_point()`. The order of layers added by `+` symbol is generally interchangeable. 

Combined with `%>%` operator, we can think of the code as a sentence. For example, take dataset `deaths08`, `%>%` (*then*) plot with `gglpot()` with the aestetics of hour of day on the x-axis, `+` (*and add a player of*) geom object `geom_histogram()`.       

```{r}
#  histogram version of the line-graph for the total number of deaths above
deaths08 %>% 
  ggplot(aes(x = hod)) + geom_histogram(binwidth = 1, color = "white") 
```

```{r}  
# summary by month of day and hour of day.
# e.g, Jan-1am, ..,Jan-11pm, Feb-1am,..., Feb-11pm, ...   
n_month_hour <- deaths08 %>%
  group_by(mod, hod) %>%
  summarise( nobs = n() )

n_month_hour %>%
  ggplot(aes(x = hod, y = nobs, color = as.factor(mod))) + 
  geom_point() 
  
# "last_plot() + " allows for adding more layers to the previous plot
last_plot() + geom_line()
```
 

### Exercise {-}

Now it is your turn. The exercise is to reproduce the above figure for the unusual causes of deaths. 

1. Download materials: [case study paper](vita.had.co.nz/papers/tidy-data.html) and [case study data](https://github.com/kotamine/piecemealR/raw/master/tidy_case_study/tidy_case_study.RData)

2.  Set working directly: `setwd(your_directory)`

3. Load libraries: `library(dplyr)`, `library(ggplot2)`, `library(MASS)` (used for fitting data by robust regression)

* Note 1: There is a minor error in the case study that the author accidentally kept several records of data from years other than 2008. This virtually has no effect on the results, and we would do the same to excatly reproduce his results.    

* Note 2: You could look at the codes in the paper itself for hints. But, the code is written with the functions of [plyr](https://cran.r-project.org/web/packages/plyr/index.html) package, which is the precesssor of `dplyr`. Do not load both `plyr` and `dplyr` libraries in the same R session; they do not seem to have good compatibility. Restart R if you accidentally loaded both.  

#### Part A. Display overall hourly deaths {-}

We will reproduce:

<img src="tidy_case_study/unusual-big.png" width="100%">

Hints:

* Filter `NA` in the hour of day (hod) variable

* Use `group_by()`,  `summarise()`, `n()` to obtain death counts by group

* Use `ggplot() + geom_line()` to produce plot  

* Use `+ labs( x = "x lable", y = "y label")` for axis labels

* see help file of `scale_y_continous()` for comma (use `?function_name` for help) 



#### Part B. Count deaths per hour, per disease {-}

We will reproduce: 

<figure>
<img src="tidy_case_study/table16.png" width="600">
</figure>

Panel (a) of the table contains the frequency (i.e. the number of rows) for each combination of hour of day (hod) and cause of death (cod), supplemented by the disease description in panel (b). Panel (c) shows the proportion (prop) of each hod-cod combination in the total deaths by the cod. Panel (d) contains the frequency and proportion (freq_all and prop_all) of the death counts by hour of day.  

That is, panel (a) is the raw counts (e.g., frequency) of observations by **each pair** of hour of day (hod) and cause of death (cod), and panel (b) makes it easy to look up the cause of death (cod).  Panel (c) converts this frequency of *hod-cod pair* into the proportion (i.e. relative frequency) in the total frequency of **cod**, so that we see how disproportinately large each  **hod-cod pair** is within the particular  **cod**. Panel (d), on the other hand, presents the frequency and relative frequency of deaths for each hour (**hod**); if each hour has the same probablity of death, we would see prop_all $\approx$ 0.042 (by 1/24).  Here we see the author's idea of identifying "unusual deaths" by comparing "prop" of each **hod-cod pairs** for its deviation from to "prop_all".  


Hints for creating panels (a) and (b)

* Use more than one variable in `group_by()` 

* Use `summarise()` with `n()` to obtain death counts by group

* Use `left_join()` to add the information from dataset `codes` 

Hints for creating panel (c)

* Use `mutate()` with `sum()` on the joined dataset 

Hints for creating panels (d) 

* Create a new data frame by using `summarise()` on the joined and mutated data frame. (`summarise()` will reduce the dimension of the data frame as its summmary, which is the basis of panel (d). Once the desired summary is created, we will merge it to the data frame of panels (a)-(c).)

* Before using `summarise()` above, use `group_by()` to specify new grouping

* First create `freq_all` via `summarise()` with `n()` and then create `prop_all` via `mutate()` with `sum()` (call this data frame `overall_freq`, which will be used again at the very end)  

* Use `left_join()` to join panels (a)-(c) and panel (d) (`overall_freq`), which we refer to as `master_hod` data frame.  

Hints for extracting the same rows as in the table 16 above 

* Create a subset of the `master_hod` data under a new name 

* Use `filter()` to select  `cod` being either  "I21", "N18", "E84", or "B16" and `hod` being greater or equal to 8 and smaller or less than 11

* Use `select()` to pick columns in a desired order and `arrange()` to sort


#### Part C. Find outliers {-}

We will reproduce: 

<img src="tidy_case_study/n-dist-raw.png" width="50%" align="left">
<img src="tidy_case_study/n-dist-log.png" width="50%" align="left">





We will create a deviation variable named `dist` by taking the mean of squared differences between `prop` and `prop_all` by cause of death (`cod`). The above figures show the the number of observations `n` and this distance measure `dist` by cause of death in the raw scale (left) and in the log scale (right).     

Hints

* Use `group_by()` and `summarise()` on the `master_hod` data frame to generate `n` with function `sum()` and `dist` by `mean((prop - prop_all)^2)`

* Filter this summary for `n > 50` and call it `devi_cod` (deviations by cause of death)

* Use `ggplot() + geom_point()` on  `devi_cod` to produce the raw-scale figure (left) 

* Additionally use `scale_x_log10()`, `scale_y_log10()`, and `geom_smooth(method = "rlm", se = FALSE)` to produce the log-scale figure (right)

* See help for `scale_x_log10()` to adjust axis labels (look for "comma") 

* Let's not worry about grids for the log-scale figure 


#### Part D. Fit data by a regression and plot residuals {-}

We reproduce:

<figure>
<img src="tidy_case_study/n-dist-resid.png" width="500">
</figure>

The figure is a plot of the regression residuals `resid` of `log(dist)` on `log(n)` against log-scale `n`. By inspection, the points lying above the holizontal line at `resid=1.5` are considered to be "unusual causes of deaths" by the author.

Here the author used the robust linear model (`rlm()`) regression, but the syntax is similar to the standard linear model regression (`lm()` ).  

Let's look at a simple example of regression by `lm()`. 

```{r}
df <- data.frame(
  x1 <-  c(1:10),
  y1 <-  c(1,3,2,4,6,5,7,5,7,8)
)

df %>% 
  ggplot(aes(x = x1, y = y1)) + geom_point() +
  geom_smooth(method = "lm", se = FALSE)

#  The geom_smooth() is estimating the following linear regression:
#  y1 = intercept + coefficient * x1 + residual
#  which is  
f1 <- lm(formula = y1 ~ x1,  data = df) 
class(f1)    # class "lm""
summary(f1)  # summary() knows how to summarise an object of class "lm" 
coefficients(f1)  # coefficient point estimate
vcov(f1)          # coefficient variance-covariance matrix
predict(f1)       # predicted (fitted) values with the estimated coefficients 
resid(f1)         # residuals:  
```


Run a regression by `rlm` with `formula = log(dist) ~ log(n)` and store the residuals in `devi_cod` data. Plot the residual against log-scale `n`. We use `rlm()` to exactly replicate the case study, but in most cases `lm()` suffices. To read more about linear regressions, see the help file of `lm()` (type `?lm`).

Hints 

*  While you should not have missing values in this case, check the dataset `devi_cod` for missing values in `dist` and `n` before running a regression.  Most regression functions, including `lm()` and `rlm()`, drop any row with missing values for the estimation model. This becomes an issue if we want to add a new column containing predicted values or residuals in the existing dataset. (When rows containing missing values are dropped, the vector generated by `predict()` or  `resid()` will be shorter than the rows of the original dataset. And when adding this as a new column to the original dataset, you need to match which rows correspond to whcih predicted or residual values.)      

* Use `ggplot() + geom_point()` structure for the plot

* Add  `+ scale_x_log10()` and `+ geom_hline(yintercept = 1.5)` 



#### Part E. Visualise unusual causes of death {-}

We reproduce:

<figure>
<img src="tidy_case_study/unusual-big.png" width="100%">
<img src="tidy_case_study/unusual-sml.png" width="100%">
</figure>

The first figure is the unusual causes of deaths in `devi_cod` with a relatively large number of deaths  (`n > 350`) and the second is that of a relatively small number of deaths (`n <= 350`). 

Using the cuttoff value `resid > 1.5`, filter `devi_cod` and call it `unusual` data frame. Join `master_hod` and `unusual` data frames. Then create two subsets with conditions  `n > 350` and `n <= 350` and plot the data. 
Hints

* Use `ggplot() + geom_line()` structure with `+ facet_warp(~ disease, ncol = 3)` 

* To include the base-line proportions representing the average of all causes of deaths, add another `geom_line(aes(...), data = overall_freq)` layer with a local `aes()` argument and a data argument. The data arument can specify another data frame to be combined (assuming the axes have the same units), and we use `overall_freq` from the panel (d) portion of Table 16 above.  

* `last_plot() %+% another_data_frame `  reproduces a plot of the same structure with a different data frame




### The Key {-}

The solution will be presented at the workshop and later posted here.  

<!--

[Solution using dplyr](https://github.com/kotamine/piecemealR/blob/master/tidy_case_study/tidy_case_study.R)

[Solution using plyr](https://github.com/kotamine/piecemealR/blob/master/tidy_case_study/tidy_case_study_plyr.R)

-->

<!-- ### Reflections


`r if (knitr:::is_html_output()) '# References {-}'`
-->


