<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Piecemeal R</title>
  <meta name="description" content="This is a R tutorial.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Piecemeal R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a R tutorial." />
  <meta name="github-repo" content="/kotamine/piecemealR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Piecemeal R" />
  
  <meta name="twitter:description" content="This is a R tutorial." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="4-1-dplyr.html">
<link rel="next" href="4-3-mixed.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.4/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-97062240-1', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Piecemeal R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome</a><ul>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html"><i class="fa fa-check"></i>About</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-intro.html"><a href="2-intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="2-1-materials.html"><a href="2-1-materials.html"><i class="fa fa-check"></i><b>2.1</b> Materials</a></li>
<li class="chapter" data-level="2.2" data-path="2-2-crafts.html"><a href="2-2-crafts.html"><i class="fa fa-check"></i><b>2.2</b> Crafts</a></li>
<li class="chapter" data-level="2.3" data-path="2-3-arts.html"><a href="2-3-arts.html"><i class="fa fa-check"></i><b>2.3</b> Arts</a></li>
<li class="chapter" data-level="2.4" data-path="2-4-more-examples-1.html"><a href="2-4-more-examples-1.html"><i class="fa fa-check"></i><b>2.4</b> More examples 1</a></li>
<li class="chapter" data-level="2.5" data-path="2-5-more-examples-2.html"><a href="2-5-more-examples-2.html"><i class="fa fa-check"></i><b>2.5</b> More examples 2</a></li>
<li class="chapter" data-level="2.6" data-path="2-6-reflections.html"><a href="2-6-reflections.html"><i class="fa fa-check"></i><b>2.6</b> Reflections</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-essentials.html"><a href="3-essentials.html"><i class="fa fa-check"></i><b>3</b> Essentials</a><ul>
<li class="chapter" data-level="3.1" data-path="3-1-cheatsheets.html"><a href="3-1-cheatsheets.html"><i class="fa fa-check"></i><b>3.1</b> Cheatsheets</a></li>
<li class="chapter" data-level="3.2" data-path="3-2-datatypes.html"><a href="3-2-datatypes.html"><i class="fa fa-check"></i><b>3.2</b> Data types</a><ul>
<li class="chapter" data-level="3.2.1" data-path="3-2-datatypes.html"><a href="3-2-datatypes.html#atomic"><i class="fa fa-check"></i><b>3.2.1</b> Atomic</a></li>
<li class="chapter" data-level="3.2.2" data-path="3-2-datatypes.html"><a href="3-2-datatypes.html#factor"><i class="fa fa-check"></i><b>3.2.2</b> Factor</a></li>
<li class="chapter" data-level="3.2.3" data-path="3-2-datatypes.html"><a href="3-2-datatypes.html#matrix"><i class="fa fa-check"></i><b>3.2.3</b> Matrix</a></li>
<li class="chapter" data-level="3.2.4" data-path="3-2-datatypes.html"><a href="3-2-datatypes.html#data-frame"><i class="fa fa-check"></i><b>3.2.4</b> Data Frame</a></li>
<li class="chapter" data-level="3.2.5" data-path="3-2-datatypes.html"><a href="3-2-datatypes.html#list"><i class="fa fa-check"></i><b>3.2.5</b> List</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="3-3-programming.html"><a href="3-3-programming.html"><i class="fa fa-check"></i><b>3.3</b> Programming</a><ul>
<li class="chapter" data-level="3.3.1" data-path="3-3-programming.html"><a href="3-3-programming.html#operator"><i class="fa fa-check"></i><b>3.3.1</b> Operator</a></li>
<li class="chapter" data-level="3.3.2" data-path="3-3-programming.html"><a href="3-3-programming.html#if-else"><i class="fa fa-check"></i><b>3.3.2</b> If else</a></li>
<li class="chapter" data-level="3.3.3" data-path="3-3-programming.html"><a href="3-3-programming.html#loop"><i class="fa fa-check"></i><b>3.3.3</b> Loop</a></li>
<li class="chapter" data-level="3.3.4" data-path="3-3-programming.html"><a href="3-3-programming.html#function"><i class="fa fa-check"></i><b>3.3.4</b> Function</a></li>
<li class="chapter" data-level="3.3.5" data-path="3-3-programming.html"><a href="3-3-programming.html#environment"><i class="fa fa-check"></i><b>3.3.5</b> Environment</a></li>
<li class="chapter" data-level="3.3.6" data-path="3-3-programming.html"><a href="3-3-programming.html#debugging"><i class="fa fa-check"></i><b>3.3.6</b> Debugging</a></li>
<li class="chapter" data-level="3.3.7" data-path="3-3-programming.html"><a href="3-3-programming.html#stat-func."><i class="fa fa-check"></i><b>3.3.7</b> Stat func.</a></li>
<li class="chapter" data-level="3.3.8" data-path="3-3-programming.html"><a href="3-3-programming.html#string-func."><i class="fa fa-check"></i><b>3.3.8</b> String func.</a></li>
<li class="chapter" data-level="3.3.9" data-path="3-3-programming.html"><a href="3-3-programming.html#set-func."><i class="fa fa-check"></i><b>3.3.9</b> Set func.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="3-4-housekeeping.html"><a href="3-4-housekeeping.html"><i class="fa fa-check"></i><b>3.4</b> Housekeeping</a><ul>
<li class="chapter" data-level="3.4.1" data-path="3-4-housekeeping.html"><a href="3-4-housekeeping.html#working-directory"><i class="fa fa-check"></i><b>3.4.1</b> Working directory</a></li>
<li class="chapter" data-level="3.4.2" data-path="3-4-housekeeping.html"><a href="3-4-housekeeping.html#r-session"><i class="fa fa-check"></i><b>3.4.2</b> R session</a></li>
<li class="chapter" data-level="3.4.3" data-path="3-4-housekeeping.html"><a href="3-4-housekeeping.html#save-load"><i class="fa fa-check"></i><b>3.4.3</b> Save &amp; load</a></li>
<li class="chapter" data-level="3.4.4" data-path="3-4-housekeeping.html"><a href="3-4-housekeeping.html#input-output"><i class="fa fa-check"></i><b>3.4.4</b> Input &amp; Output</a></li>
<li class="chapter" data-level="3.4.5" data-path="3-4-housekeeping.html"><a href="3-4-housekeeping.html#updating"><i class="fa fa-check"></i><b>3.4.5</b> Updating</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-piecemeal-top.html"><a href="4-piecemeal-top.html"><i class="fa fa-check"></i><b>4</b> Piecemeal Topics</a><ul>
<li class="chapter" data-level="4.1" data-path="4-1-dplyr.html"><a href="4-1-dplyr.html"><i class="fa fa-check"></i><b>4.1</b> Unusual Deaths in Mexico</a><ul>
<li class="chapter" data-level="" data-path="4-1-dplyr.html"><a href="4-1-dplyr.html#materials-1"><i class="fa fa-check"></i>Materials</a></li>
<li class="chapter" data-level="" data-path="4-1-dplyr.html"><a href="4-1-dplyr.html#arts-crafts"><i class="fa fa-check"></i>Arts &amp; Crafts</a></li>
<li class="chapter" data-level="" data-path="4-1-dplyr.html"><a href="4-1-dplyr.html#exercise"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="4-1-dplyr.html"><a href="4-1-dplyr.html#the-key"><i class="fa fa-check"></i>The Key</a></li>
<li class="chapter" data-level="" data-path="4-1-dplyr.html"><a href="4-1-dplyr.html#reflections-1"><i class="fa fa-check"></i>Reflections</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="4-2-boot.html"><a href="4-2-boot.html"><i class="fa fa-check"></i><b>4.2</b> Action, Romance, and Chicks</a><ul>
<li class="chapter" data-level="" data-path="4-2-boot.html"><a href="4-2-boot.html#materials-2"><i class="fa fa-check"></i>Materials</a></li>
<li class="chapter" data-level="" data-path="4-2-boot.html"><a href="4-2-boot.html#t-test"><i class="fa fa-check"></i>t-test</a></li>
<li class="chapter" data-level="" data-path="4-2-boot.html"><a href="4-2-boot.html#bootstrapping"><i class="fa fa-check"></i>Bootstrapping</a></li>
<li class="chapter" data-level="" data-path="4-2-boot.html"><a href="4-2-boot.html#linear-models"><i class="fa fa-check"></i>Linear Models</a></li>
<li class="chapter" data-level="" data-path="4-2-boot.html"><a href="4-2-boot.html#exercise-1"><i class="fa fa-check"></i>Exercise</a></li>
<li class="chapter" data-level="" data-path="4-2-boot.html"><a href="4-2-boot.html#the-key-1"><i class="fa fa-check"></i>The Key</a></li>
<li class="chapter" data-level="" data-path="4-2-boot.html"><a href="4-2-boot.html#reflections-2"><i class="fa fa-check"></i>Reflections</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="4-3-mixed.html"><a href="4-3-mixed.html"><i class="fa fa-check"></i><b>4.3</b> Demo. Mixed Effects Models and LSMEANS</a><ul>
<li class="chapter" data-level="" data-path="4-3-mixed.html"><a href="4-3-mixed.html#mixed-effect-models"><i class="fa fa-check"></i>Mixed Effect Models</a></li>
<li class="chapter" data-level="" data-path="4-3-mixed.html"><a href="4-3-mixed.html#visualizing-model-fit"><i class="fa fa-check"></i>Visualizing Model Fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-resources.html"><a href="5-resources.html"><i class="fa fa-check"></i><b>5</b> Resources</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org/yihui/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Piecemeal R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="boot" class="section level2">
<h2><span class="header-section-number">4.2</span> Action, Romance, and Chicks</h2>
<div id="materials-2" class="section level3 unnumbered">
<h3>Materials</h3>
<p>This session covers <strong>t-test</strong>, <strong>bootstrapping</strong>, and <strong>linear regressions</strong> in the same context, so that you can learn these concepts together and how to apply them in R.</p>
<p>We will use a dataset on movies.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies2 &lt;-<span class="st"> </span>movies <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(title, year, budget, rating, Action, Romance) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">   </span><span class="kw">filter</span>((Action <span class="op">==</span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>Romance <span class="op">==</span><span class="dv">1</span>),
          <span class="op">!</span>( Action <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>Romance <span class="op">==</span><span class="st"> </span><span class="dv">1</span>), 
          budget <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1970</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">budget =</span> budget<span class="op">/</span><span class="dv">10</span><span class="op">^</span><span class="dv">6</span>) 
<span class="kw">summary</span>(movies2)</code></pre></div>
<pre><code>##     title                year          budget            rating     
##  Length:1206        Min.   :1970   Min.   :  0.001   Min.   :1.500  
##  Class :character   1st Qu.:1992   1st Qu.:  3.500   1st Qu.:5.025  
##  Mode  :character   Median :1998   Median : 15.000   Median :6.000  
##                     Mean   :1996   Mean   : 27.549   Mean   :5.902  
##                     3rd Qu.:2002   3rd Qu.: 40.000   3rd Qu.:6.800  
##                     Max.   :2005   Max.   :200.000   Max.   :9.800  
##      Action          Romance      
##  Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :1.0000   Median :0.0000  
##  Mean   :0.5887   Mean   :0.4113  
##  3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.0000</code></pre>
<p>The extracted data <code>movies2</code> contain IMDB ratings of Action and Romance movies (excluding those of both Action and Romance genres) that are released between 1970 and 2005 and have known budgets. Action and Romance movies are about 59% and 41% of the data respectively. The average rating is 5.9.</p>
<p>Let’s look at the distribution of the release years and ratings in this dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies2<span class="op">$</span>year <span class="op">%&gt;%</span><span class="st"> </span>table</code></pre></div>
<pre><code>## .
## 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 
##   12   10   11    8   11    7    9   10    7    4   11   16   10    8   13 
## 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 
##   27   17   18   15   22   22   19   20   30   32   51   55   64   77   64 
## 2000 2001 2002 2003 2004 2005 
##   80   94  110  103  103   36</code></pre>
<p>We see that more data are available for years 1999-2004 than other years.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>rating)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.5</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;dodgerblue&quot;</span>)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>The distribution of rating is somewhat skewed to the left.</p>
<p>Let’s see how Action and Romance movies compare.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies2 &lt;-<span class="st"> </span>movies2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">genre =</span> <span class="kw">ifelse</span>(Action<span class="op">==</span><span class="dv">1</span>, <span class="st">&quot;Action&quot;</span>, <span class="st">&quot;Romance&quot;</span>))
movies2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>rating)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.5</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;dodgerblue&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(genre <span class="op">~</span><span class="st"> </span>.)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movies2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(rating),
            <span class="dt">sd =</span> <span class="kw">sd</span>(rating),
            <span class="dt">n =</span> <span class="kw">n</span>())</code></pre></div>
<pre><code>## # A tibble: 2 × 4
##     genre     mean       sd     n
##     &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;
## 1  Action 5.729859 1.419404   710
## 2 Romance 6.147581 1.262879   496</code></pre>
<p>Romance genre gets a slightly higher average rating than Action. For the sake of discussion, suppose that <code>movies2</code> is the <strong>population</strong> (or the <strong>universe</strong>) of our movie data, meaning that <em>it contains all possible observations (movies) that fit our criteria</em> (i.e. Action or Romance movies released in 1970-2005 with known budgets). Then, the <em>population</em> mean ratings for Action and Romance movies are 5.73 and 6.15 respectively.</p>
<p>Now consider a sampling world. In almost all situations, the researcher does not have <strong>population data</strong> and has to work with <strong>a sample</strong> drawn from the population. Knowing that what we have is <em>only a sample</em>, we make <strong>statistical inferences</strong> for the property of the population. For example, using a sample of Action and Romance movies, we can compare their average ratings at certain statistical significance.</p>
<p>Let’s simulate our sampling world. Here we randomly draw 30 observations from each genre and calculate summary statistics.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2017</span>)  <span class="co"># Fix a starting point of random number generations for reproducibility </span>

movie_sample &lt;-<span class="st"> </span>movies2 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(genre) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">30</span>)

movie_sample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>rating)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.5</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;dodgerblue&quot;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">facet_grid</span>(genre <span class="op">~</span><span class="st"> </span>.)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movie_sample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(genre) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(rating),
            <span class="dt">std_dev =</span> <span class="kw">sd</span>(rating),
            <span class="dt">n =</span> <span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">3</span>)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">genre</th>
<th align="right">mean</th>
<th align="right">std_dev</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Action</td>
<td align="right">5.730</td>
<td align="right">1.248</td>
<td align="right">30</td>
</tr>
<tr class="even">
<td align="left">Romance</td>
<td align="right">6.333</td>
<td align="right">1.208</td>
<td align="right">30</td>
</tr>
</tbody>
</table>
<p>Here is an another view;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movie_sample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>( <span class="dt">x =</span> genre, <span class="dt">y =</span> rating)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>To compare the mean ratings between genres, a common practice is to test the equality of means, say <span class="math inline">\(\mu_A\)</span> and <span class="math inline">\(\mu_R\)</span> of Action and Romance movies respectively.</p>
<p>The null and alternative hypotheses are:</p>
<p><span class="math inline">\(H_0: \mu_A = \mu_R\)</span> (equivalently, <span class="math inline">\(\mu_A - \mu_R = 0\)</span>)</p>
<p><span class="math inline">\(H_A: \mu_A \neq \mu_R\)</span></p>
<!--### Arts & Crafts {-}-->
</div>
<div id="t-test" class="section level3 unnumbered">
<h3>t-test</h3>
<p>Let’s begin with reviewing some fundamental concepts of statistics. Let <span class="math inline">\(y_{i}\)</span> is an <em>independently and identically distributed (i.i.d.)</em> random variable for observation <span class="math inline">\(i = 1, .., N\)</span> drawn from some distribution with population mean <span class="math inline">\(\mu = E[y_i]\)</span> and standard deviation <span class="math inline">\(\sigma = \sqrt{E[(y_i - \mu)^2]}\)</span> where <span class="math inline">\(E[.]\)</span> is an expectation operator over the random variable. The sample mean and standard deviation of <span class="math inline">\(y_{i}\)</span> are defined as <span class="math display">\[\bar{y} = \frac{\sum_i y_i}{N}, \quad  s =\sqrt{\frac{\sum_i (y_{i} - \bar{y})^2}{(N-1)}}.\]</span></p>
<p>We commonly take the average <span class="math inline">\(\bar{y}\)</span>, which serves as an unbiased estimate of <span class="math inline">\(\mu\)</span>. Yet, how close is <span class="math inline">\(\bar{y}\)</span> to <span class="math inline">\(\mu\)</span>? The statistical theory gives us a probabilistic answer for inferring population mean <span class="math inline">\(\mu\)</span>. For example, if we know that <span class="math inline">\(y_i\)</span> is <em>normally distributed</em> with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, then it follows that the sample mean <span class="math inline">\(\bar{y}\)</span> is normally distributed with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma/\sqrt{N}\)</span>. The distribution of an estimate like this is called <strong>sampling distribution</strong>, and in special cases it is exactly known.</p>
<p><strong>With known* <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span></strong>, we know how fast the sample mean <span class="math inline">\(\bar{y}\)</span> approaches to the population mean <span class="math inline">\(\mu\)</span> as the sample size <span class="math inline">\(N\)</span> increases. This is done by calculating the z-statistic<br />
<span class="math display">\[z = \frac{\bar{y} - \mu}{\sigma/\sqrt N}\]</span></p>
<p>and comparing it to <strong>the standard normal distribution</strong> table. In other words, to make an inference, we look at the relationship of <span class="math inline">\(\bar{y}\)</span>, <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma\)</span>, and <span class="math inline">\(N\)</span> as described in the z-statistic, for which the shape of the distribution is known. This allows us to infer the representation of observed <span class="math inline">\(\bar{y}\)</span> if we were to repeat random samples of size <span class="math inline">\(N\)</span> and calculate the sample mean many times.</p>
<p>In most situations, <strong>we do not know <span class="math inline">\(\mu\)</span> or <span class="math inline">\(\sigma\)</span> of the population</strong>, and we are unsure whether the underlying distribution is really normal. But, that’s okay. We can still make inferences for the population mean <span class="math inline">\(\mu\)</span>.</p>
<p>Under some regularity conditions (e.g. the existence of a finite mean and variance of the random variable), the <strong>Central Limit Theorem</strong> tells us that regardless the underlying distribution, the sampling distribution of <span class="math inline">\(\bar{y}\)</span> is <em>approximately normal</em>.</p>
<p>In a world with <em>unknown</em> <span class="math inline">\(\mu\)</span> or <span class="math inline">\(\sigma\)</span>, we approximate the standard normal distribution with <strong>a Student’s t distribution</strong>. The t-statistic is calculated as <span class="math display">\[t = \frac{\bar{y} - \mu}{s/\sqrt N}\]</span></p>
<p>where <span class="math inline">\(s\)</span> is the consistent estimate of <span class="math inline">\(\sigma\)</span>, and we compare it to the t distribution table at <span class="math inline">\(N-1\)</span> degrees of freedom (one degree of freedom is reduced for the estimate <span class="math inline">\(s\)</span>). The Student’s t distribution is fatter-tailed than the standard normal distribution (due to the <em>estimated standard error</em> on the denominator), and it approaches to the standard normal distribution as the sample size <span class="math inline">\(N\)</span> increases. For given significance level <span class="math inline">\(\alpha\)</span>, the <span class="math inline">\(1-\alpha\)</span> confidence interval is</p>
<p><span class="math display">\[t_{N, 1-\alpha/2} \le \frac{\bar{y} - \mu}{s/\sqrt N} \le t_{N, \alpha/2}\]</span></p>
<p>where <span class="math inline">\(t_{N, 1-\alpha/2}\)</span> and <span class="math inline">\(t_{N, 1-\alpha/2}\)</span> are the lower and upper bounds of the t-statistic and are found in the t-distribution table. Since the t-distribution is symmetric, <span class="math inline">\(- t_{N, 1-\alpha/2} = t_{N, 1-\alpha/2}\)</span>. For example, at <span class="math inline">\(\alpha=0.05\)</span> and <span class="math inline">\(N&gt;1000\)</span>, we have <span class="math inline">\(t_{N, 1-\alpha/2} \approx -1.96\)</span> and <span class="math inline">\(t_{N, 1-\alpha/2}=1.96\)</span>. Thus, for a large <span class="math inline">\(N\)</span>, the confidence interval of <span class="math inline">\(\mu\)</span> is given by<br />
<span class="math display">\[ \bar{y} -  1.96 \:\: s/\sqrt{N} \le  \mu \le \bar{y} + 1.96 \:\: s/\sqrt{N}.\]</span></p>
<p>Let’s get back to the comparison of ratings between genres. How do we test our hypothesis <span class="math inline">\(\mu_A = \mu_R\)</span>? Intuitively, we can make estimates of <span class="math inline">\(\mu_A\)</span> and <span class="math inline">\(\mu_R\)</span> by the corresponding sample means <span class="math inline">\(\bar{y}_A\)</span> and <span class="math inline">\(\bar{y}_R\)</span>. Then, it’s a matter of making statistical inferences about <span class="math inline">\(\bar{y}_A - \bar{y}_R\)</span> for how close they would be to <span class="math inline">\(\mu_A - \mu_R\)</span>. We calculate the t-statistic of <span class="math inline">\(\bar{y}_A - \bar{y}_R\)</span> and infer the probability of rejecting <span class="math inline">\(H_0: \mu_A - \mu_R = 0\)</span>.</p>
<p>Let <span class="math inline">\(\bar{y}_{A}\)</span> and <span class="math inline">\(s_A\)</span> be the sample mean and standard deviation of ratings for Action movies and <span class="math inline">\(\bar{y}_{R}\)</span> and <span class="math inline">\(s_R\)</span> be those for Romance movies. A typical approach called Welch’s t-test statistic uses <span class="math display">\[t = \frac{\bar{y}_A - \bar{y}_R}{s_\Delta}\]</span></p>
<p>where <span class="math display">\[s_\Delta = \sqrt{\frac{s_A^2}{N_A} + \frac{s^2_R}{N_R}}\]</span></p>
<p>is sort of a joint standard deviation of <span class="math inline">\(y_{iA} - y_{iR}\)</span>. Its degree of freedom has a somewhat complicated form but is approximately <span class="math inline">\((N_A-1) + (N_R-1)\)</span> in many situations. For your information (not need to memorize), it is formally given as <span class="math display">\[d.f. = \frac{s^2_\Delta}{(s_A^2/N_A)^2/(N_A - 1) + (s_R^2/N_R)^2/(N_R - 1) }.\]</span></p>
<p>The Welch’s t-test statistic can be manually calculated as follows.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#  Welch&#39;s t-stat for the mean difference of two groups </span>
mean_ratings &lt;-<span class="st"> </span>movie_sample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(genre) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(rating), <span class="dt">sd =</span> <span class="kw">sd</span>(rating))

sample_diff &lt;-<span class="st"> </span>mean_ratings<span class="op">$</span>mean[<span class="dv">1</span>] <span class="op">-</span><span class="st"> </span>mean_ratings<span class="op">$</span>mean[<span class="dv">2</span>]
sample_diff_sd &lt;-<span class="st"> </span><span class="kw">sqrt</span>(mean_ratings<span class="op">$</span>sd[<span class="dv">1</span>]<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">30</span> <span class="op">+</span><span class="st"> </span>mean_ratings<span class="op">$</span>sd[<span class="dv">2</span>]<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">30</span>)  <span class="co"># N = 30</span>
sample_t &lt;-<span class="st"> </span>sample_diff<span class="op">/</span>sample_diff_sd

<span class="kw">c</span>(sample_diff, sample_diff_sd, sample_t) </code></pre></div>
<pre><code>## [1] -0.6033333  0.3171889 -1.9021261</code></pre>
<p>The observed mean difference is -0.603, for which the t-statistic is -1.902 at approximately 58 degrees of freedom.</p>
<p>Let’s visualize this t-statistic against its theoretical distribution, which can be approximated by many random draws from the Student’s t distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">many_t_df58 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">t =</span> <span class="kw">rt</span>(<span class="dv">10</span><span class="op">^</span><span class="dv">6</span>, <span class="dv">58</span>))  
    <span class="co"># one million random draws from t-dist with 58 d.f. </span>
many_t_df58 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>t)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;white&#39;</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> sample_t) <span class="co"># add vertical line at -1.902</span></code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>The t distribution is centered at zero and has symmetric tails. We can think of the area of each bar representing the probability that a random draw of t-stat falls in that bin, and the total area of bars on the left of our t-statistic (-1.902) represents the probability that a random draw of t-stat is smaller than -1.902.</p>
<p>By applying the two-tail t test, we can calculate the probability that a random draw of t-stat is more extreme than our t-statistic (i.e., being located toward either of the tails);</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">nrow</span>(<span class="kw">subset</span>(many_t_df58, <span class="kw">abs</span>(t)<span class="op">&gt;=</span><span class="st"> </span><span class="kw">abs</span>(sample_t)))<span class="op">/</span><span class="kw">nrow</span>(many_t_df58)</code></pre></div>
<pre><code>## [1] 0.061964</code></pre>
<p>Let’s visualize this probability;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">many_t_df58 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>t)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;white&#39;</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">data =</span> <span class="kw">subset</span>(many_t_df58, <span class="kw">abs</span>(t)<span class="op">&gt;=</span><span class="st"> </span><span class="kw">abs</span>(sample_t)), 
                 <span class="dt">color=</span><span class="st">&#39;white&#39;</span>, <span class="dt">fill=</span><span class="st">&quot;red&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> sample_t)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>where the highlighted area represents the probability of <strong>type I</strong> error, or the rejection of the null hypothesis <span class="math inline">\(H_0\)</span> when it is in fact true, and represents the <strong>p-value</strong> (0.062 in this case). If we set our tolerance level for making a type I error at the probability of 10% or less (<span class="math inline">\(\alpha = 0.1\)</span>), we conclude that we <em>reject the null hypothesis <span class="math inline">\(H_0\)</span></em> (i.e., a finding of a statistically significant difference in ratings between Action and Romance genres) since the p-value is smaller than <span class="math inline">\(\alpha\)</span>. If we set our tolerance level at <span class="math inline">\(\alpha = 0.05\)</span>, we <em>fail to reject <span class="math inline">\(H_0\)</span></em> (no statistically significant effect).</p>
<p>We can visualize how the probability of rejections (called <strong>rejection regions</strong>) associated with <span class="math inline">\(\alpha = 0.1\)</span> (orange below) and <span class="math inline">\(\alpha = 0.05\)</span> (green) compare to our t-statistic;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">many_t_df58 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>t)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="dt">color=</span><span class="st">&#39;white&#39;</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="co"># rejection regions with critical val for a = 0.1</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">data =</span> <span class="kw">subset</span>(many_t_df58, <span class="kw">abs</span>(t)<span class="op">&gt;=</span><span class="st"> </span><span class="kw">abs</span>(<span class="kw">qt</span>(.<span class="dv">95</span>,<span class="dv">58</span>))),  
                 <span class="dt">color=</span><span class="st">&#39;white&#39;</span>, <span class="dt">fill=</span><span class="st">&quot;orange&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">  </span><span class="co"># rejection regions with  critical val for a = 0.05</span>
<span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">data =</span> <span class="kw">subset</span>(many_t_df58, <span class="kw">abs</span>(t)<span class="op">&gt;=</span><span class="st"> </span><span class="kw">abs</span>(<span class="kw">qt</span>(.<span class="dv">975</span>,<span class="dv">58</span>))), 
                 <span class="dt">color=</span><span class="st">&#39;white&#39;</span>, <span class="dt">fill=</span><span class="st">&quot;green&quot;</span>, <span class="dt">binwidth =</span> <span class="fl">0.1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> sample_t)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Now that we know what the Welch’s t-test does, we can simply use R’s function to conduct a t-test;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movie_sample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">with</span>(<span class="kw">t.test</span>( rating <span class="op">~</span><span class="st"> </span>genre ))  <span class="co"># using &quot;formula&quot; input</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  rating by genre
## t = -1.9021, df = 57.937, p-value = 0.06213
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.23827054  0.03160388
## sample estimates:
##  mean in group Action mean in group Romance 
##              5.730000              6.333333</code></pre>
<p>Recall that we started with knowing that the population mean rating for Romance is slightly higher than for Action. Here, it seems reasonable that a random sample of 30 observations from each genre leads us to find a statistically significant difference at the 10% level.</p>
</div>
<div id="bootstrapping" class="section level3 unnumbered">
<h3>Bootstrapping</h3>
<p>Now we will introduce a concept of <strong>bootstrapping</strong>. Recall that <strong>our statistic, say <span class="math inline">\(\bar{y}\)</span>, conceptually has its distribution</strong>, depending on the version of random sample that we happen to draw. The idea here is to mimic the process of having many versions of random samples through simulations, so that we generate <strong>a simulated distribution of the statistic</strong>. Then, we can make statistical inferences <strong>without invoking the statistical theory</strong> of the approximate distribution via the Central Limit Theorem.</p>
<p>There are many ways to conduct bootstrapping. For simplicity, we will use some of the most common practices.</p>
<p>First, we make many random draws of <span class="math inline">\(y_{iA}\)</span> and <span class="math inline">\(y_{iR}\)</span> from our sample <code>movie_sample</code> with replacement (i.e., each time the drawn observation is put back into the pool) where subscript <span class="math inline">\(i\)</span> stands for an observation of movie record. We can use <code>do()</code> from <code>mosaic</code> package and <code>sample_n()</code> from <code>dplyr</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2017</span>)

boot1 &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(<span class="dv">5000</span>) <span class="op">*</span><span class="st"> </span><span class="co"># repeat the following expression ({...}) for 5000 times </span>
<span class="st">  </span>({  movie_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">group_by</span>(genre) <span class="op">%&gt;%</span>
<span class="st">       </span><span class="co"># sample 30 obs from each genre with replacement</span>
<span class="st">      </span><span class="kw">sample_n</span>(<span class="dv">30</span>, <span class="dt">replace=</span><span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">summarize</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(rating),
                <span class="dt">sd =</span> <span class="kw">sd</span>(rating),
                <span class="dt">n =</span><span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">data.frame</span>()
  })

<span class="kw">head</span>(boot1)</code></pre></div>
<pre><code>##     genre     mean        sd  n .row .index
## 1  Action 5.536667 1.0473228 30    1      1
## 2 Romance 6.173333 1.3284508 30    2      1
## 3  Action 5.683333 1.3164957 30    1      2
## 4 Romance 6.760000 1.0682244 30    2      2
## 5  Action 5.630000 0.8317617 30    1      3
## 6 Romance 6.333333 1.1931799 30    2      3</code></pre>
<p>The column <code>.index</code> shows the index of bootstrap replications, and the column <code>.row</code> nested in <code>.index</code> gives the indicator of calculated results by genre within each replication.</p>
<p>Next, we calculate the bootstrap version of our estimates such as <span class="math inline">\(\bar{y}_A - \bar{y}_R\)</span> and Welch’s t statistic.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot1_w &lt;-<span class="st">  </span>boot1 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>.row) <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># get rid of .row column </span>
<span class="st">  </span><span class="kw">reshape</span>(<span class="dt">idvar=</span> <span class="st">&quot;.index&quot;</span>, <span class="dt">timevar=</span><span class="st">&quot;genre&quot;</span>,     <span class="co"># reshape into a &quot;wide-form&quot; dataset </span>
           <span class="dt">direction=</span><span class="st">&quot;wide&quot;</span>)
<span class="kw">head</span>(boot1_w)</code></pre></div>
<pre><code>##    .index mean.Action sd.Action n.Action mean.Romance sd.Romance n.Romance
## 1       1    5.536667 1.0473228       30     6.173333   1.328451        30
## 3       2    5.683333 1.3164957       30     6.760000   1.068224        30
## 5       3    5.630000 0.8317617       30     6.333333   1.193180        30
## 7       4    5.480000 1.0768408       30     6.170000   1.303087        30
## 9       5    5.513333 1.1340295       30     6.293333   1.235937        30
## 11      6    5.950000 1.2601998       30     6.440000   1.131554        30</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot1_w  &lt;-<span class="st"> </span>boot1_w <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">bt_diff  =</span> (mean.Action <span class="op">-</span><span class="st"> </span>mean.Romance),  <span class="co"># difference </span>
    <span class="dt">bt_sd =</span> <span class="kw">sqrt</span>(sd.Action<span class="op">^</span><span class="dv">2</span><span class="op">/</span>n.Action <span class="op">+</span><span class="st"> </span>sd.Romance<span class="op">^</span><span class="dv">2</span><span class="op">/</span>n.Romance),
    <span class="dt">bt_t =</span> bt_diff<span class="op">/</span>bt_sd                <span class="co"># Welch&#39;s t-stat</span>
    ) </code></pre></div>
<p>Here is how sample estimate <code>sample_diff</code> compares with the histogram of its bootstrap counterpart <code>bt_diff</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot1_w <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bt_diff, <span class="dt">fill =</span> bt_diff <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> sample_diff) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Here the <code>bt_diff</code> values that are greater than zero are marked by a different color (green) since they suggest the opposite conclusion that the mean rating is higher for Action than for Romance. Depending on the random draw of a bootstrap replication, one could have the opposite result in some of the times. The question is how often that happens.</p>
<p>Using the bootstrap estimates, we can estimate the confidence interval in a few ways. For example, to estimate a 95% confidence interval, one can take the 2.5th and 97.5th percentiles of the distribution shown above in the histogram.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># confidence interval</span>
<span class="kw">quantile</span>(boot1_w<span class="op">$</span>bt_diff, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))  <span class="co"># version 1</span></code></pre></div>
<pre><code>##        2.5%       97.5% 
## -1.20333333  0.01333333</code></pre>
<p>Another approach is to calculate a bootstrap standard deviation and apply <span class="math inline">\(t_{df,\alpha/2} \le (\bar{y}_A - \bar{y}_R)/s_{bt} \le t_{df,1-\alpha/2}\)</span> where <span class="math inline">\(\bar{y}_A - \bar{y}_R\)</span> is the mean difference in ratings between Action and Romance movies, <span class="math inline">\(s_{bt}\)</span> is an estimated standard deviation of <span class="math inline">\(\bar{y}_A - \bar{y}_R\)</span>, and <span class="math inline">\(- t_{df,\alpha/2}=t_{df,\alpha/2}=2.00\)</span> for the t distribution with 58 degrees of freedom. Note that here we do not need <span class="math inline">\(\sqrt{N}\)</span> in the confidence interval calculation (unlike the above discussion where <span class="math inline">\(s\)</span> was the standard deviation of rating individual <span class="math inline">\(y_i\)</span> instead of the standard deviation of <em>the average</em>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample_diff_sd_boot &lt;-<span class="st"> </span><span class="kw">sd</span>(boot1_w<span class="op">$</span>bt_diff)
<span class="co"># version 2</span>
<span class="kw">c</span>(sample_diff <span class="op">-</span><span class="st"> </span><span class="fl">2.00</span> <span class="op">*</span><span class="st"> </span>sample_diff_sd_boot, sample_diff <span class="op">+</span><span class="st"> </span><span class="fl">2.00</span> <span class="op">*</span><span class="st"> </span>sample_diff_sd_boot) </code></pre></div>
<pre><code>## [1] -1.21881724  0.01215058</code></pre>
<p>For two-tail test, we focus on extreme values on both tails of the distribution. We can visualize this by centering the above graph at <code>sample_diff</code> and examining the values on both tails away from the center.</p>
<p>By extending the fill code <code>bt_diff &gt; 0</code> from the previous histogram, we can subtract <code>sample_diff</code> and take the absolute values. Then the new version of fill code is; <code>abs(bt_diff - sample_diff) &gt; abs(sample_diff)</code>.</p>
<p>Essentially, we are approximating the distribution of <span class="math inline">\((\bar{y}_A-\bar{y}_R) - (\mu_A -\mu_R)\)</span> (i.e., <code>sample_diff</code> compared to the population difference) by the distribution of <span class="math inline">\((\bar{y}^*_A-\bar{y}^*_R) - (\bar{y}_A-\bar{y}_R )\)</span> (i.e., bootstrap estimate <span class="math inline">\(\bar{y}^*_A-\bar{y}^*_R =\)</span> <code>bt_diff</code> compared to <code>sample_diff</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot1_w <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bt_diff <span class="op">-</span><span class="st"> </span>sample_diff, 
             <span class="dt">fill =</span> <span class="kw">abs</span>(bt_diff <span class="op">-</span><span class="st"> </span>sample_diff) <span class="op">&gt;</span><span class="st"> </span><span class="kw">abs</span>(sample_diff))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>This centered histogram with colored tails helps us visualize whether our sample estimate <code>sample_diff</code> is representative; how closely did the bootstrap estimates fall centered around <code>sample_diff</code>? The areas of the extreme values correspond to the rejection regions for the two-tail t-test, and the middle part corresponds to the confidence interval. By summing the area of the rejection regions, we can estimate the p-value, representing the probability that a bootstrap estimate falls in either of the colored tails;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># p-value</span>
boot1_w <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">with</span>(<span class="kw">sum</span>(<span class="kw">abs</span>(bt_diff <span class="op">-</span><span class="st"> </span>sample_diff) <span class="op">&gt;</span><span class="st"> </span><span class="kw">abs</span>(sample_diff))<span class="op">/</span><span class="kw">length</span>(bt_diff))   </code></pre></div>
<pre><code>## [1] 0.0512</code></pre>
<p>Another version of bootstrapping would be to simulate Welch’s t-statistic directly, instead of simulating the mean difference. An estimate in the form of t-statistic has a <strong>pivotal quality</strong> (meaning that the distribution of the statistic does not depend on unknown parameters). Welch’s t-statistic follows the Student’s t distribution with a given degree of freedom, which does not depend on any unknown parameter such as the population mean or variance. A pivotal statistic is suitable for bootstrapping.</p>
<p>Here are the parallel results for bootstrapping Welch’s t-statistic.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">boot1_w <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bt_t, <span class="dt">fill =</span> bt_t <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> sample_t) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>To convert a confidence interval of Welch’s t-statistic <span class="math inline">\((\bar{y}_A - \bar{y}_R)/s_\Delta\)</span> into a confidence interval of the difference in mean ratings <span class="math inline">\(\bar{y}_A - \bar{y}_R\)</span>, we multiply the former by <span class="math inline">\(s_\Delta=\)</span> <code>sample_diff_sd</code>;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># confidence interval</span>
<span class="kw">quantile</span>(boot1_w<span class="op">$</span>bt_t, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>)) <span class="op">*</span><span class="st"> </span>sample_diff_sd  <span class="co"># version 1 </span></code></pre></div>
<pre><code>##        2.5%       97.5% 
## -1.31094136  0.01345958</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample_t_sd_boot &lt;-<span class="st"> </span>boot1_w <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">with</span>(<span class="kw">sd</span>(bt_t <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(bt_t)))  
<span class="co"># version 2</span>
<span class="kw">c</span>(sample_t <span class="op">-</span><span class="st"> </span><span class="fl">2.00</span> <span class="op">*</span><span class="st"> </span>sample_t_sd_boot, sample_t <span class="op">+</span><span class="st"> </span><span class="fl">2.00</span> <span class="op">*</span><span class="st"> </span>sample_t_sd_boot)  <span class="op">*</span><span class="st"> </span>sample_diff_sd  </code></pre></div>
<pre><code>## [1] -1.27547455  0.06880788</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># centered at observed Welch&#39;s t-statistic</span>
boot1_w <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bt_t <span class="op">-</span><span class="st"> </span>sample_t, <span class="dt">fill =</span> <span class="kw">abs</span>(bt_t <span class="op">-</span><span class="st"> </span>sample_t) <span class="op">&gt;</span><span class="st"> </span><span class="kw">abs</span>(sample_t))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;top&quot;</span>)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># p-value </span>
boot1_w <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">with</span>(<span class="kw">sum</span>(<span class="kw">abs</span>(bt_t <span class="op">-</span><span class="st"> </span>sample_t) <span class="op">&gt;</span><span class="st"> </span><span class="kw">abs</span>(sample_t))<span class="op">/</span><span class="kw">length</span>(bt_t))  </code></pre></div>
<pre><code>## [1] 0.0716</code></pre>
</div>
<div id="linear-models" class="section level3 unnumbered">
<h3>Linear Models</h3>
<p>Let’s extend our discussion on bootstrapping to linear regression. While the formal discussion of linear models has not been covered so far in this site, we can develop an intuitive understanding on how they works.</p>
<p>Start with the following model <span class="math display">\[ y_i = a_0 + b_1 x_{i} + \varepsilon_i\]</span> where <span class="math inline">\(y_i\)</span> is the dependent variable of observation <span class="math inline">\(i\)</span>, <span class="math inline">\(x_i\)</span> is an independent variable, <span class="math inline">\(a_0\)</span> and <span class="math inline">\(b_1\)</span> are parameters for the intercept and the slope of <span class="math inline">\(x\)</span>, and <span class="math inline">\(\varepsilon_i\)</span> is the residual error term. Depending on the assumption of the error term <span class="math inline">\(\varepsilon_i\)</span>, we could estimate different models on the same equation. One of the key assumptions we need is that the error <span class="math inline">\(\varepsilon_i\)</span> is uncorrelated with the independent variable <span class="math inline">\(x_i\)</span>.</p>
<p>Here is an example of estimating the Ordinary Least Squares (OLS) via <code>lm()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d0 &lt;-<span class="st"> </span><span class="kw">data.frame</span>( <span class="dt">y =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">3</span>),
                  <span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">4</span>))

<span class="kw">lm</span>( y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> d0) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = d0)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.3966 -0.3683  0.2207  0.5145  0.8972 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   1.2213     0.5109   2.390 0.053994 .  
## x             0.6469     0.0856   7.557 0.000279 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8338 on 6 degrees of freedom
## Multiple R-squared:  0.9049, Adjusted R-squared:  0.8891 
## F-statistic: 57.11 on 1 and 6 DF,  p-value: 0.0002787</code></pre>
<p>Coefficient estimates are <span class="math inline">\(a_0 = 1.2213\)</span> and <span class="math inline">\(b_1 = 0.6469\)</span> with the standard errors of <span class="math inline">\(sd(a_0) = 0.5109\)</span> and <span class="math inline">\(sd(b1) = 0.0856\)</span>, suggesting that the t-values of <span class="math inline">\(2.390\)</span> and <span class="math inline">\(7.557\)</span> for testing whether these coefficients are statistically different from zero, or <span class="math inline">\(H_0: a_0=0\)</span> and <span class="math inline">\(H_0: b_1 =0\)</span>. The standard error for the residual is estimated with the assumption that <span class="math inline">\(\varepsilon_i\)</span> is <em>i.i.d.</em> normal with mean zero and some standard deviation <span class="math inline">\(\sigma\)</span>. “Pr(&gt;|t|)” shows the p-values of the coefficient estimates, and the statistical significance is indicated with symbols “***”, “**” etc. Let’s not worry about other metrics here.</p>
<p>Let’s visualize the above regression;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d0 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>( <span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>With only two variables, a plot like this gives us a clear picture of how the regression relates to the data points. The straight line is the fitted regression equation <span class="math inline">\(\widehat{a}_0 + \widehat{b}_1 x_i\)</span> where hat <span class="math inline">\(\widehat{}\)</span> notation represents an estimate. The vertical distance (and its direction) from the fitted line is the residual <span class="math inline">\(\widehat{\varepsilon_i}=y_i - \widehat{a}_0 + \widehat{b}_1 x_i\)</span>. The OLS estimates are <strong>the best linear unbiased estimators (BLUE)</strong>.</p>
<p>Now, let <span class="math inline">\(y_{ij}\)</span> be the rating of movie <span class="math inline">\(i\)</span> in genre <span class="math inline">\(j\)</span> where <span class="math inline">\(j\)</span> is either <span class="math inline">\(A\)</span> (Action) or <span class="math inline">\(R\)</span> (Romance). Also, let <code>1(cond)</code> be the indicator function that takes a value of one if condition <code>cond</code> is true and zero otherwise. Then, we can test the mean difference in movie ratings between Action and Romance by a linear regression. <span class="math display">\[ y_{ij} = b_A \: 1(j=A) + b_R \: 1(j=R) + \varepsilon_{ij}\]</span> where the means of Action and Romance movies are estimated by <span class="math inline">\(b_A\)</span> and <span class="math inline">\(b_R\)</span> respectively. Under the standard OLS assumptions, <span class="math inline">\(b_A\)</span> and <span class="math inline">\(b_R\)</span> are equivalent to the sample means (calculated by the usual summing and dividing by the number of observations), and the estimates of the variances for <span class="math inline">\(\hat{b}_A\)</span> and <span class="math inline">\(\hat{b}_R\)</span> are obtained by matrix algebra (which we will cover in a future session).</p>
<p>For rotational brevity, this equation may be written as<br />
<span class="math display">\[ y_{ij} = \alpha_j + \varepsilon_{ij}\]</span> where <span class="math inline">\(\alpha_j\)</span> is <span class="math inline">\(\alpha_A = b_A\)</span> for <span class="math inline">\(j=A\)</span> and <span class="math inline">\(\alpha_R = b_R\)</span> for <span class="math inline">\(j=R\)</span>. This model yields the following;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># &quot;0 +&quot; eliminates the intercept </span>
<span class="kw">lm</span>(rating <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>genre, <span class="dt">data =</span> movie_sample) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() </code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rating ~ 0 + genre, data = movie_sample)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.3333 -0.6583 -0.1300  0.7942  3.2700 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## genreAction    5.7300     0.2243   25.55   &lt;2e-16 ***
## genreRomance   6.3333     0.2243   28.24   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.228 on 58 degrees of freedom
## Multiple R-squared:  0.9615, Adjusted R-squared:  0.9602 
## F-statistic:   725 on 2 and 58 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Note that the t-statistics test hypotheses <span class="math inline">\(H_0: b_A = 0\)</span> and <span class="math inline">\(H_0: b_R = 0\)</span>, which differ from our interest, <span class="math inline">\(H_0: b_A = b_R\)</span>.</p>
<p>We can rewrite the above equation as<br />
<span class="math display">\[ y_{ij} = a_0  + \beta_R \: 1(j=R) + \varepsilon_{ij}\]</span></p>
<p>where <span class="math inline">\(\beta_R = b_R - b_A\)</span>.</p>
<p>Moreover, we can rewrite this as <span class="math display">\[ y_{ij} = a_0  + \alpha_j + \varepsilon_{ij}\]</span> where <span class="math inline">\(\alpha_A\)</span> serves as a reference group and hence is excluded from the coefficient estimates.</p>
<p>This yields;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ols1 &lt;-<span class="st"> </span><span class="kw">lm</span>( rating <span class="op">~</span><span class="st"> </span>genre, <span class="dt">data =</span> movie_sample)  
<span class="kw">summary</span>(ols1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rating ~ genre, data = movie_sample)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.3333 -0.6583 -0.1300  0.7942  3.2700 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    5.7300     0.2243  25.548   &lt;2e-16 ***
## genreRomance   0.6033     0.3172   1.902   0.0621 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.228 on 58 degrees of freedom
## Multiple R-squared:  0.05872,    Adjusted R-squared:  0.04249 
## F-statistic: 3.618 on 1 and 58 DF,  p-value: 0.06212</code></pre>
<p>where the estimate of <span class="math inline">\(\alpha_R\)</span> is equivalent with the calculated difference <code>sample_diff</code>, and its t-statistic is approximately the same as <code>sample_t</code> above. The sign is switched since our estimate here is <span class="math inline">\(b_R - b_A\)</span> instead of <span class="math inline">\(b_A - b_R\)</span>.</p>
<p>Like the above output from Welch’s t-statistic, <strong>based on the statistical theory</strong> the OLS output here provides the estimate of standard errors for coefficients. <strong>Now let’s derive our estimate of standard errors by applying bootstrapping to the OLS model.</strong></p>
<p>In doing so, we create several functions here. The first two functions extract “formula” and the dependent variable from a <code>lm</code> class object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">getFormula &lt;-<span class="st"> </span><span class="cf">function</span>(model) <span class="kw">gsub</span>(<span class="st">&quot;()&quot;</span>,<span class="st">&quot;&quot;</span>, model<span class="op">$</span>call[<span class="dv">2</span>])  <span class="co"># gsub() substitues characters</span>
<span class="kw">getFormula</span>(ols1)</code></pre></div>
<pre><code>## [1] &quot;rating ~ genre&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">getDependentVar &lt;-<span class="st"> </span><span class="cf">function</span>(model) {
  str &lt;-<span class="st"> </span><span class="kw">getFormula</span>(model) 
  <span class="kw">gsub</span>(<span class="st">&quot; &quot;</span>,<span class="st">&quot;&quot;</span>, <span class="kw">substr</span>(str, <span class="dv">1</span>, (<span class="kw">regexpr</span>(<span class="st">&quot;~&quot;</span>,str)[<span class="dv">1</span>]<span class="op">-</span><span class="dv">1</span>)))　 <span class="co"># substr() takes a substring</span>
  }
<span class="kw">getDependentVar</span>(ols1)</code></pre></div>
<pre><code>## [1] &quot;rating&quot;</code></pre>
<p>The next function takes a <code>lm</code> class object (i.e., an output of <code>lm()</code>) with a specified number of bootstrap replications and produces bootstrap versions of the coefficient estimates as an output.</p>
<ul>
<li><p>Assume that the distribution of <span class="math inline">\(\varepsilon_i\)</span> is a normal distribution with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\hat{\sigma}^2\)</span> where <span class="math inline">\(\hat{\sigma} = \sum\hat{\varepsilon}^2_i/(N-k)\)</span> is the OLS estimate of <span class="math inline">\(\sigma\)</span> with <span class="math inline">\(N-k\)</span> degrees of freedom (d.f. is the number of observations minus the number of parameters).</p></li>
<li><p>Generate a bootstrapped dependent variable by combining the predicted part of the linear model <span class="math inline">\(\hat{a}_0 + \hat{\alpha}_j\)</span> and an random draw of bootstrap error term <span class="math inline">\(\varepsilon^b_i\)</span>, or <span class="math inline">\(y^b_{ij} = \hat{a}_0 + \hat{\alpha}_j + \varepsilon^b_i\)</span>.</p></li>
<li><p>In each bootstrap replication <span class="math inline">\(b=1, .., B\)</span>, replace <span class="math inline">\(y_{ij}\)</span> with its bootstrap counterpart <span class="math inline">\(y^b_{ij}\)</span> and run the OLS estimation, and we repeat this process for <span class="math inline">\(B\)</span> times (we set <span class="math inline">\(B=5000\)</span>).</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">run_ols_boot &lt;-<span class="st"> </span><span class="cf">function</span>(lm_rlt, <span class="dt">num_do =</span> <span class="dv">5000</span>) {
  
  <span class="co"># calculate the standard deviation of the residuals</span>
  N &lt;-<span class="st"> </span><span class="kw">length</span>(lm_rlt<span class="op">$</span>residuals)
  sd_res &lt;-<span class="st"> </span>(<span class="kw">sum</span>(lm_rlt<span class="op">$</span>residuals<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span>lm_rlt<span class="op">$</span>df.residual) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sqrt</span>()
  dep_var &lt;-<span class="st"> </span><span class="kw">getDependentVar</span>(lm_rlt)

  <span class="kw">do</span>(num_do) <span class="op">*</span><span class="st"> </span>
<span class="st">    </span>({  
        data_bt &lt;-<span class="st"> </span>lm_rlt<span class="op">$</span>model
        <span class="co"># replace the dependent variable with its bootstrap counterpart</span>
        data_bt[[dep_var]] &lt;-<span class="st"> </span>lm_rlt<span class="op">$</span>fitted.values <span class="op">+</span><span class="st">    </span><span class="co">#  the predicted component</span>
<span class="st">          </span><span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> sd_res)     <span class="co">#  random draws from the error distribution </span>
         
        <span class="co"># run the OLS model with the same formula but with a new, bootstrap dataset  </span>
        ols_bt &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">as.formula</span>(<span class="kw">getFormula</span>(lm_rlt)), <span class="dt">data =</span> data_bt)  
        <span class="kw">coef</span>(ols_bt)  <span class="co"># get coefficients </span>
    }) 
}

<span class="kw">set.seed</span>(<span class="dv">2017</span>)
<span class="co"># run bootstrap with our function </span>
bt_est_ols1 &lt;-<span class="st"> </span><span class="kw">run_ols_boot</span>(ols1, <span class="dv">5000</span>) </code></pre></div>
<p>Let’s compare the estimates of standard errors between the default OLS and our bootstrap results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample_ols1 &lt;-<span class="st"> </span><span class="kw">tidy</span>(ols1) <span class="co"># summary of the original OLS estimates </span>

bt_sd_ols1 &lt;-<span class="st"> </span><span class="kw">apply</span>(bt_est_ols1, <span class="dv">2</span>, sd) <span class="co"># calculate bootstrap standard errors </span>
bt_ols1 &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dt">coeff =</span> sample_ols1<span class="op">$</span>estimate, <span class="co"># copy the coeff from the OLS result</span>
                 <span class="dt">sd =</span> bt_sd_ols1,              <span class="co"># use bootstrap standard errors</span>
                 <span class="dt">tstat =</span> sample_ols1<span class="op">$</span>estimate<span class="op">/</span>bt_sd_ols1) </code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># OLS estimates with statistical inferences by statistic theory</span>
sample_ols1 </code></pre></div>
<pre><code>##           term  estimate std.error statistic      p.value
## 1  (Intercept) 5.7300000 0.2242864 25.547688 2.999063e-33
## 2 genreRomance 0.6033333 0.3171889  1.902126 6.212427e-02</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># OLS estimates with statistical inferences by bootstrapping</span>
bt_ols1 </code></pre></div>
<pre><code>##                  coeff        sd     tstat
## Intercept    5.7300000 0.2224649 25.756876
## genreRomance 0.6033333 0.3137163  1.923181</code></pre>
<p>In this case they are pretty close.</p>
<p>Let’s visualize this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample_Romance &lt;-<span class="st"> </span>sample_ols1<span class="op">$</span>estimate[<span class="dv">2</span>]
bt_est_ols1 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> genreRomance <span class="op">-</span><span class="st"> </span>sample_Romance, 
             <span class="dt">fill =</span> (<span class="kw">abs</span>(genreRomance <span class="op">-</span><span class="st"> </span>sample_Romance) <span class="op">&gt;=</span><span class="st"> </span><span class="kw">abs</span>(sample_Romance)))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">bins =</span> <span class="dv">40</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>Here are the estimated confidence interval and p-value by bootstrapping.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># confidence interval by bootstrapping</span>
<span class="kw">quantile</span>(bt_est_ols1<span class="op">$</span>genreRomance, <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))  <span class="co"># version 1 </span></code></pre></div>
<pre><code>##        2.5%       97.5% 
## -0.01474822  1.22427177</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">c</span>(<span class="st">&#39;2.5%&#39;</span> =<span class="st"> </span>sample_Romance <span class="op">-</span><span class="st"> </span><span class="fl">2.00</span> <span class="op">*</span><span class="st"> </span>bt_sd_ols1[<span class="dv">2</span>], 
  <span class="st">&#39;97.5%&#39;</span> =<span class="st"> </span>sample_Romance  <span class="op">+</span><span class="st"> </span><span class="fl">2.00</span> <span class="op">*</span><span class="st"> </span>bt_sd_ols1[<span class="dv">2</span>])   <span class="co"># version 2</span></code></pre></div>
<pre><code>##  2.5%.genreRomance 97.5%.genreRomance 
##         -0.0240993          1.2307660</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># p-value </span>
bt_est_ols1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">with</span>(
  <span class="kw">sum</span>(<span class="kw">abs</span>(genreRomance <span class="op">-</span><span class="st"> </span>sample_Romance) <span class="op">&gt;</span><span class="st"> </span><span class="kw">abs</span>(sample_Romance))<span class="op">/</span><span class="kw">length</span>(genreRomance)
  ) </code></pre></div>
<pre><code>## [1] 0.0548</code></pre>
<p>These results are also very close to what we saw for the Welch’s t-statistic and its bootstrap estimates above.</p>
<p>Now let’s take a step further into <strong>regression modeling</strong>.</p>
<p>The regression allows us to utilize additional variables in the model. Let’s try adding a linear effect of movie budget. It seems reasonable to hypothesize that the higher the budget, the better a movie can be since the director can employ famous actors and actresses, expensive movie settings, or computer graphics. Then, our estimation equation becomes<br />
<span class="math display">\[ y_{ij} = a_0  + \alpha_j + \beta_1 \:budget_i + \varepsilon_{ij}.\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ols2 &lt;-<span class="st"> </span><span class="kw">lm</span>( rating <span class="op">~</span><span class="st"> </span>genre <span class="op">+</span><span class="st"> </span>budget,  <span class="dt">data =</span> movie_sample)
<span class="kw">summary</span>(ols2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rating ~ genre + budget, data = movie_sample)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.20205 -0.69226 -0.07884  0.71999  2.92299 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  5.424309   0.304038  17.841   &lt;2e-16 ***
## genreRomance 0.753435   0.330186   2.282   0.0263 *  
## budget       0.006944   0.004717   1.472   0.1465    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.216 on 57 degrees of freedom
## Multiple R-squared:  0.09319,    Adjusted R-squared:  0.06137 
## F-statistic: 2.929 on 2 and 57 DF,  p-value: 0.06155</code></pre>
<p>The new estimate of <span class="math inline">\(\alpha_R\)</span> is 0.753 with standard error 0.330. A common interpretation goes like this; <em>the estimated relative effect of Romance to Action genre on the movie rating is 0.753 at the 5% significance level, while controlling for the effect of movie budget.</em> Note that the effect of budget itself estimation.</p>
<p>Recall that an important assumption is that the error term is uncorrelated with independent variables. Here the above model relies on the assumption;<br />
<span class="math display">\[E[\varepsilon_{ij} \:| \: genre_j,\: budget_i] = E[\varepsilon_{ij} ] = 0\]</span> where <span class="math inline">\(E[v | u]\)</span> denotes the conditional mean of <span class="math inline">\(v\)</span> given <span class="math inline">\(u\)</span>. It says that the information of <span class="math inline">\(genre_j\)</span> and <span class="math inline">\(budget_i\)</span> does not affect the mean of the error distribution. There is no definitive way to test this assumption, and it could be violated in several ways. The most relevant case here is what is known as <strong>omitted variable bias</strong>; some unobserved attributes of the movie (which are conceptually a part of the error <span class="math inline">\(\varepsilon_{ij}\)</span>) may be correlated with both <span class="math inline">\(y_{ij}\)</span> and <span class="math inline">\(budget_i\)</span>.</p>
<p>For example, many people might agree that the use of explosions make action movies more exciting and romance movies more dramatic. Then, suppose that the story taking place in a war-time setting can increase the movie rating and also inflate the movie budget. In such a case, the OLS estimates <em>could be</em> biased via the omitted variable (an indicator for having a war-time setting). In a future session, we will talk more about the potential sources of bias.</p>
<p>The bottom line: every model is incorrect when applied to some real-world data, and the “error term” captures the deviation from the model prediction. The correctness is always a matter of degree, and that’s why we care about the error term; how is the predicted error distributed? Inspecting the predicted error for its properties is important. However, <em>the true error in regression analysis is essentially conceptual</em> unless the analyst knows exactly how the data are generated. Randomized control trials (RCT) give the researcher confidence in such data generating process. In observational studies, the statistical modeling of observed data tends to an art as much as a science, requiring careful considerations of regression models.</p>
<p>Returning to our topic, let’s add another variable to our model? The movies in the dataset were released between 1970 and 2005, during which movie-goers’ preferences or movie production costs may have changed systematically. By accounting for a quadratic time trend, we estimate the following <span class="math display">\[ y_{ij} = a_0  + \alpha_j + \beta_1 \:budget_i + \beta_2 \: year_i  + \beta_3 \: year^2_i + \varepsilon_{ij}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ols3 &lt;-<span class="st"> </span><span class="kw">lm</span>( rating <span class="op">~</span><span class="st"> </span>genre <span class="op">+</span><span class="st"> </span>budget <span class="op">+</span><span class="st"> </span>year <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(year<span class="op">^</span><span class="dv">2</span>),  <span class="dt">data =</span> movie_sample) 
  <span class="co"># I() allows the user to construct a new variable on the fly. </span>
<span class="kw">summary</span>(ols3)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rating ~ genre + budget + year + I(year^2), data = movie_sample)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.02921 -0.70194  0.03311  0.60606  3.00738 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   5.108e+03  7.024e+03   0.727   0.4701  
## genreRomance  7.918e-01  3.254e-01   2.434   0.0182 *
## budget        8.452e-03  4.700e-03   1.798   0.0776 .
## year         -5.087e+00  7.058e+00  -0.721   0.4741  
## I(year^2)     1.268e-03  1.773e-03   0.715   0.4776  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.196 on 55 degrees of freedom
## Multiple R-squared:  0.1544, Adjusted R-squared:  0.09288 
## F-statistic:  2.51 on 4 and 55 DF,  p-value: 0.05214</code></pre>
<p>When accounting for the time trend, the coefficient for budget is statistically significant at the 10% level, and the residual standard error is slightly reduced from 1.216 to 1.196. That seems like an improvement, and the model equation looks sensible. Now do you feel more confident in these results?</p>
<p>Let’s see if we can conduct a further check. We assumed a common quadratic time trend for Action and Romance movies. Let’s take a step back and visualize the time trend in the data using <code>ggplot() + geom_jitter() + geom_smooth()</code>. By default <code>geom_smooth()</code> uses a flexible form to fit the relationship between x and y variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movie_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>( <span class="dt">x =</span> year, <span class="dt">y =</span> rating, <span class="dt">color =</span> genre)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_jitter</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span>F)</code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39;</code></pre>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>We can immediately spot that in <em>our sample</em>, we only have a few movies from the 1970-1984 period. Also, we see that the time trend seems to be shifted around year 2000.</p>
<p>Let’s set aside those older movies in our model. We can also control for the impact of movie budget (via <span class="math inline">\(\hat{\beta_1} \: budget_i\)</span> with our estimate <span class="math inline">\(\hat{\beta_1}\)</span> and replacing it with the sample average (<span class="math inline">\(\hat{\beta_1} \: E[budget_i]\)</span>). And here is an updated version holding the effect of budget constant at the sample mean;</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">movie_sample <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1985</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>( <span class="dt">x =</span> year, 
              <span class="dt">y =</span> rating <span class="op">-</span><span class="st"> </span>ols3<span class="op">$</span>coefficients[<span class="st">&#39;budget&#39;</span>]<span class="op">*</span>(budget <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(budget)), 
              <span class="dt">color =</span> genre)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39;</code></pre>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>We still see some shift in time trend around 2000, at which the trends between Action and Romance movies start to diverge. Year 2000 may be the beginning of increasing computer graphics due to its decreasing production costs. That could be a turning point, especially for Action movies.</p>
<p>Now what can we do?</p>
<p>Assigning different time trends for Action and Romance would be a possibility if our objective were to simply find the model that best fits the data. However, that is not be a good idea if we are interested in comparing the average ratings of the two genres. After all, the genre-specific time trend is a part of the difference between genres that we want to compare. The best we could do seems that we let the time trend vary before and after 2000, while assuming the common trend for both genres.</p>
<p>Here is a relatively simple solution.<br />
<span class="math display">\[ 
\begin{align} 
\nonumber y_{ij} &amp;= a_0  + \alpha_{j} + \beta_1 \:budget_i + \beta_2 \: year_i  + \beta_3 \: year^2_i 
\\ 
\nonumber &amp;+ (a_{0,M}  + \alpha_{j, M} + \beta_{1,M} \:budget_i  + \beta_{2,M} \: year_i  + \beta_{3,M} \: year^2_i) \:M_i + \varepsilon_{ij} 
\end{align}
\]</span> where <span class="math inline">\(M_i = 1(year_i\ge2000)\)</span> is an indicator variable for post-millennium years. The items in parenthesis multiplied by <span class="math inline">\(M_i\)</span> are the interaction terms between the baseline variables and the millennium indicator. These additional terms captures the additional effects that only apply to post-millennium movies. The interaction terms can be constructed with * symbol in <code>lm()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># filter data and also remove group-class attribute  </span>
movie_sample2 &lt;-<span class="st"> </span>movie_sample <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(year<span class="op">&gt;=</span><span class="dv">1985</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ungroup</span>()

<span class="co"># prepare variables </span>
movie_sample2 &lt;-<span class="st"> </span>movie_sample2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year_sq =</span> year<span class="op">^</span><span class="dv">2</span>, 
         <span class="dt">ge2000 =</span> <span class="kw">ifelse</span>(year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">2000</span>, <span class="dv">1</span>, <span class="dv">0</span>), 
         <span class="dt">year_ge2000 =</span> year <span class="op">*</span><span class="st"> </span>ge2000,
         <span class="dt">year_sq_ge2000 =</span> year_sq <span class="op">*</span><span class="st"> </span>ge2000,
         <span class="dt">budget_ge2000 =</span> budget <span class="op">*</span><span class="st"> </span>ge2000)

ols4 &lt;-<span class="st"> </span><span class="kw">lm</span>( rating <span class="op">~</span><span class="st"> </span>genre<span class="op">*</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>ge2000) <span class="op">+</span>
<span class="st">               </span>year <span class="op">+</span><span class="st"> </span>year_sq <span class="op">+</span><span class="st"> </span>
<span class="st">               </span>year_ge2000 <span class="op">+</span><span class="st"> </span>year_sq_ge2000 <span class="op">+</span><span class="st"> </span>
<span class="st">               </span>budget <span class="op">+</span><span class="st"> </span>budget_ge2000,  
            <span class="dt">data =</span> movie_sample2)
<span class="kw">summary</span>(ols4)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = rating ~ genre * (1 + ge2000) + year + year_sq + 
##     year_ge2000 + year_sq_ge2000 + budget + budget_ge2000, data = movie_sample2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.8226 -0.6920 -0.1258  0.6058  3.5089 
## 
## Coefficients:
##                       Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         -1.649e+05  5.796e+04  -2.845 0.006515 ** 
## genreRomance         1.801e+00  4.946e-01   3.642 0.000662 ***
## ge2000              -8.242e+04  4.076e+05  -0.202 0.840627    
## year                 1.656e+02  5.820e+01   2.846 0.006498 ** 
## year_sq             -4.159e-02  1.461e-02  -2.847 0.006482 ** 
## year_ge2000          8.120e+01  4.072e+02   0.199 0.842791    
## year_sq_ge2000      -2.000e-02  1.017e-01  -0.197 0.844965    
## budget               1.448e-02  8.152e-03   1.776 0.082040 .  
## budget_ge2000       -4.906e-03  1.100e-02  -0.446 0.657487    
## genreRomance:ge2000 -1.497e+00  7.143e-01  -2.096 0.041371 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.119 on 48 degrees of freedom
## Multiple R-squared:  0.3259, Adjusted R-squared:  0.1995 
## F-statistic: 2.578 on 9 and 48 DF,  p-value: 0.01649</code></pre>
<p>The results show that accounting for the effects of budget and distinct time trends for two time spans 1985-1999 and 2000-2005, on average the Romance movie has a 1.801 (<span class="math inline">\(\alpha \le 0.001\)</span>) higher rating during 1985-1999 and 0.304 ( = 1.801 - 1.497) higher rating during 2000-2005, compared to the Action movie.</p>
<p>To see whether the total effect for the latter period (<span class="math inline">\(\alpha_R + \alpha_{R,M}\)</span>) is statistically different from zero, we can use Wald test (using a function from <code>aod</code> package). The standard notation is <span class="math display">\[H_0: \Gamma \beta = r\]</span> where <span class="math inline">\(\beta\)</span> is the coefficients of the linear model, <span class="math inline">\(\Gamma\)</span> is a matrix that specifies linear combinations of <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(r\)</span> is a column vector of constants. In this case, we only have a single equation for <span class="math inline">\(H_0\)</span> (i.e. a single row), namely <span class="math inline">\(H_0: \alpha_R + \alpha_{R, M} = 0\)</span>. This corresponds to <span class="math inline">\(\Gamma = [0\: 1\: 0\: 0\: 0\: 0\: 0\: 0\: 0\: 1]\)</span> (the second and tenth coefficients corresponding to <span class="math inline">\(\alpha_R\)</span> and <span class="math inline">\(\alpha_{R, M}\)</span>) and <span class="math inline">\(r = [0\: 0\: 0\: 0\: 0\: 0\: \: 0\: 0\: 0\: 0]&#39;\)</span>. The test statistic <span class="math inline">\(\alpha_R + \alpha_{R, M}\)</span> approximately follows the chi-square distribution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">gamma &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">nrow=</span><span class="dv">1</span>)
<span class="kw">wald.test</span>(<span class="dt">Sigma =</span> <span class="kw">vcov</span>(ols4), <span class="dt">b=</span><span class="kw">coef</span>(ols4), <span class="dt">L=</span>gamma)</code></pre></div>
<pre><code>## Wald test:
## ----------
## 
## Chi-squared test:
## X2 = 0.35, df = 1, P(&gt; X2) = 0.56</code></pre>
<p>which shows the p-value of 0.56. Thus, we fail to reject <span class="math inline">\(H_0: \alpha_R + \alpha_{R, M} = 0\)</span> at the 10% significance level. This means that there is not significant difference between genres for the 2000-2005 period.</p>
<p>We can visualize the results in data plots. First, let’s observe raw data points of ratings and predicted ratings by the model separately. Then, we overlay time trends of predicted ratings (curves) on top of raw data points. Here we use the default option of <code>geom_smooth()</code> to fit curves.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate predicted ratings </span>
movie_sample2 &lt;-<span class="st"> </span>movie_sample2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">fit =</span> <span class="kw">fitted.values</span>(ols4))

movie_plot0 &lt;-<span class="st"> </span>
<span class="st">  </span>movie_sample2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> rating,
         <span class="dt">color =</span> genre)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_jitter</span>() 

<span class="co"># raw-data ratings </span>
movie_plot0 </code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predicted ratings + fitted curves on predicted ratings </span>
movie_sample2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> fit,
         <span class="dt">color =</span> genre)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39;</code></pre>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-42-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># raw-data ratings + fitted curves on predicted ratings </span>
movie_plot0 <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_smooth</span>(
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> fit,
         <span class="dt">color =</span> genre),
    <span class="dt">se=</span><span class="ot">FALSE</span>)</code></pre></div>
<pre><code>## `geom_smooth()` using method = &#39;loess&#39;</code></pre>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-42-3.png" width="672" /></p>
<p>Using the predicted parameters <span class="math inline">\(\widehat{\beta}_{1}\)</span> and <span class="math inline">\(\widehat{\beta}_{1,M}\)</span>, we can further account for the varying effects of budget (<span class="math inline">\(\widehat{\beta}_1 \:budget_i + \widehat{\beta}_{1,M} \:budget_i \: M_i\)</span>) by replacing them with the sample average (<span class="math inline">\(\widehat{\beta}_1 \:E[budget_i] + \widehat{\beta}_{1,M} \:E[budget_i | M_i] \: M_i\)</span>). This shows the prediction while holding the effect of budgets at the sample mean. Additionally, we can exactly fit our specification of two-segment quadratic time trends</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generating rating data at the sample mean budget</span>
movie_sample2 &lt;-<span class="st"> </span>movie_sample2 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">fit =</span> <span class="kw">fitted.values</span>(ols4),
    <span class="dt">budget_eff_adj =</span> <span class="op">-</span><span class="st"> </span>ols4<span class="op">$</span>coefficients[<span class="st">&#39;budget&#39;</span>]<span class="op">*</span>(budget <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(budget)) <span class="op">+</span>
<span class="st">           </span><span class="op">-</span><span class="st"> </span>ols4<span class="op">$</span>coefficients[<span class="st">&#39;budget_ge2000&#39;</span>]<span class="op">*</span>(budget_ge2000 <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(budget_ge2000)),
  <span class="dt">rating2 =</span> rating <span class="op">+</span><span class="st"> </span>budget_eff_adj,
  <span class="dt">fit2 =</span> fit <span class="op">+</span><span class="st"> </span>budget_eff_adj
  )

movie_plot1 &lt;-
<span class="st">  </span>movie_sample2 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> rating2, 
         <span class="dt">color =</span> genre)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_jitter</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;simulated rating (at mean budget)&quot;</span>)

<span class="co"># simulated ratings at the sample mean budget</span>
movie_plot1 </code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predicted ratings and excat fitted curves at the sample mean budget</span>
movie_sample2 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> fit2, 
         <span class="dt">color =</span> genre)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(
    <span class="dt">data =</span>movie_sample2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(year <span class="op">&lt;</span><span class="st"> </span><span class="dv">2000</span>),
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> fit2,
         <span class="dt">color =</span> genre),
    <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>), 
    <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="co"># add fit2 curve for year &gt;= 2000 </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(
    <span class="dt">data =</span>movie_sample2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">2000</span>),
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> fit2,
         <span class="dt">color =</span> genre),
    <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>), 
    <span class="dt">se=</span><span class="ot">FALSE</span>) </code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-43-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulated ratings and excat fitted curves at the sample mean budget</span>
movie_plot1 <span class="op">+</span>
<span class="st">  </span><span class="co"># add fit2 curve for year &lt; 2000 </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(
    <span class="dt">data =</span>movie_sample2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(year <span class="op">&lt;</span><span class="st"> </span><span class="dv">2000</span>),
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> fit2,
         <span class="dt">color =</span> genre),
    <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>), 
    <span class="dt">se=</span><span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="co"># add fit2 curve for year &gt;= 2000 </span>
<span class="st">  </span><span class="kw">geom_smooth</span>(
    <span class="dt">data =</span>movie_sample2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(year <span class="op">&gt;=</span><span class="st"> </span><span class="dv">2000</span>),
    <span class="kw">aes</span>( <span class="dt">x =</span> year, 
         <span class="dt">y =</span> fit2,
         <span class="dt">color =</span> genre),
    <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>), 
    <span class="dt">se=</span><span class="ot">FALSE</span>) </code></pre></div>
<p><img src="04-02-boot_files/figure-html/unnamed-chunk-43-3.png" width="672" /></p>
<p>The first plot shows how the data would appear when holding the budget level constant at the sample mean. The second plot shows how the exact fitted curves match the predicted ratings again at the sample mean budget. The third plot combines the two, showing the variation in the data and the model fit while holding the budget effect constant.</p>
<!-- ```{r} -->
<!-- movie_sample2 <- movie_sample2 %>%  -->
<!--   group_by(year, genre) %>% -->
<!--   mutate(y25 = quantile(rating2, .25, na.rm=TRUE), -->
<!--          y75 = quantile(rating2, .75, na.rm=TRUE), -->
<!--          y50 = quantile(rating2, .50, na.rm=TRUE)) %>%  -->
<!--   ungroup() -->
<!-- # simulated ratings and excat fitted curves at the sample mean budget -->
<!-- movie_plot2  <-  -->
<!--   movie_sample2 %>%  -->
<!--   ggplot( -->
<!--     aes( x = year,  -->
<!--          y = y50, -->
<!--          ymin = y25, -->
<!--          ymax = y75, -->
<!--          color = genre)) +  -->
<!--   geom_point() + geom_errorbar() +   -->
<!--   labs(y = "simulated rating (25th-75th percentile range)")  -->
<!-- movie_plot2 -->
<!-- movie_plot2 +  -->
<!--   # add fit2 curve for year < 2000  -->
<!--   geom_smooth( -->
<!--     data =movie_sample2 %>% filter(year < 2000), -->
<!--     aes( x = year,  -->
<!--          y = fit2, -->
<!--          color = genre), -->
<!--     method="lm", formula = y ~ x + I(x^2),  -->
<!--     se=FALSE) + -->
<!--   # add fit2 curve for year >= 2000  -->
<!--   geom_smooth( -->
<!--     data =movie_sample2 %>% filter(year >= 2000), -->
<!--     aes( x = year,  -->
<!--          y = fit2, -->
<!--          color = genre), -->
<!--     method="lm", formula = y ~ x + I(x^2),  -->
<!--     se=FALSE)  -->
<!-- ``` -->
<p>In summary, we find that accounting for time trends and movie budgets, the Romance movie has a 1.801 (<span class="math inline">\(\alpha ≤0.001\)</span>) higher rating than the Action movie for 1985-1999, but the difference is insignificant for 2000-2005. The results from the two sample t-test and various regression models may be correct in their own assumptions, but we see that the conclusions can differ depending on how we execute the analysis. As researchers, rarely do we ask the right question in our first try, and that is why the tools of and intuitions for exploratory data analysis are so valuable.</p>
</div>
<div id="exercise-1" class="section level3 unnumbered">
<h3>Exercise</h3>
<p>Now it is your turn.</p>
<ol style="list-style-type: decimal">
<li><p>Download materials: We will use the same <a href="https://github.com/kotamine/piecemealR/raw/master/bootstrap/movies2.RData">movie2 data</a> data as shown above</p></li>
<li><p>Set working directly: <code>setwd(your_directory)</code></p></li>
<li><p>Load libraries: <code>library(dplyr)</code>, <code>library(ggplot2)</code>, <code>library(broom)</code>, <code>library(tidyr)</code>, <code>library(mosaic)</code>, <code>library(lme4)</code></p></li>
</ol>
<div id="part-a-observe-the-central-limit-theorem-clt" class="section level4 unnumbered">
<h4>Part A: Observe the Central Limit Theorem (CLT)</h4>
<p>Load <code>movies2</code> data, which we treat as the <em>population</em>. Let rating <span class="math inline">\(y_{ij}\)</span> denote observation <span class="math inline">\(i\)</span> in genre <span class="math inline">\(j=A\)</span>, <span class="math inline">\(R\)</span> for Action or Romance.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Calculate population means <span class="math inline">\(\mu_{A}\)</span> and <span class="math inline">\(\mu_{R}\)</span> and standard errors <span class="math inline">\(\sigma_{A}\)</span> and <span class="math inline">\(\sigma_{R}\)</span> for Action and Romance movies.</p></li>
<li><p>Calculate the population mean and standard deviation of difference <span class="math inline">\(y_{iA} - y_{iR}\)</span>. Hint: the variance of <a href="https://en.wikipedia.org/wiki/Variance#Sum_of_uncorrelated_variables_.28Bienaym.C3.A9_formula.29">the sum of uncorrelated variables</a> is <span class="math inline">\(Var[a + b] = Var[a]\)</span> and <span class="math inline">\(Var[b]\)</span> for variables <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p></li>
<li><p>What is the predicted distribution of the sample mean difference <span class="math inline">\(\bar{y}_{A} - \bar{y}_{R}\)</span> by the CLT?</p></li>
<li><p>Draw a random sample of 30 observations from each genre and summarize them for stats (mean, sd, and number of observations). The sampling function in <code>dplyr</code> is <code>sample_n()</code>. Hint: Look back to see what we did above and copy the procedure; having the same data format is important for the later part of the exercise.</p></li>
<li><p>Turn the previous step d into a function, for which the input argument is a sample size and the output is the summary statistics by genre. Call it <code>my_movie_samples()</code>.</p></li>
<li><p>Apply this function to generate a set of 100 bootstrap replications using <code>mosaic::do(100) * { function(N=30) }</code>.</p></li>
<li><p>Reshape the bootstrap results via <code>reshape_movie_samples()</code>, plot its density distribution via <code>density_sample_movies()</code>, and calculate summary statistics via <code>stats_sample_movies()</code> using the following functions;</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reshape_movie_samples &lt;-<span class="st"> </span><span class="cf">function</span>(bt_samples) {
  bt_samples <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st">  </span><span class="co"># don&#39;t forget to use data.frame()</span>
<span class="st">    </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="op">-</span>.row) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">reshape</span>(<span class="dt">idvar=</span> <span class="st">&quot;.index&quot;</span>, <span class="dt">timevar=</span><span class="st">&quot;genre&quot;</span>,
            <span class="dt">direction=</span><span class="st">&quot;wide&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">bt_diff  =</span> (mean.Action <span class="op">-</span><span class="st"> </span>mean.Romance))  
}

density_sample_movies &lt;-<span class="st"> </span><span class="cf">function</span>(rehsaped_samples, N, B) {
  rehsaped_samples <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bt_diff)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="dt">adjust =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> .<span class="dv">75</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>pop_diff) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(rehsaped_samples<span class="op">$</span>bt_diff), <span class="dt">color =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> pop_diff, <span class="dt">color =</span> <span class="st">&quot;yellow&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="co"># CTL prediction mean</span>
<span class="st">    </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, <span class="dt">colour =</span> <span class="st">&quot;yellow&quot;</span>, <span class="dt">size =</span><span class="dv">1</span>, <span class="co"># CTL prediction distribution </span>
                  <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> pop_diff,
                              <span class="dt">sd =</span> pop_sigma<span class="op">/</span><span class="kw">sqrt</span>(rehsaped_samples<span class="op">$</span>n.Action[<span class="dv">1</span>]))) <span class="op">+</span>
<span class="st">     </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">paste0</span>(<span class="st">&quot;Bootstrop: &quot;</span>, B, <span class="st">&quot;,  Num observations:&quot;</span>, N ))
}

stats_sample_movies &lt;-<span class="st"> </span><span class="cf">function</span>(reshaped_samples) {
  reshaped_samples <span class="op">%&gt;%</span><span class="st">   </span>
<span class="st">    </span><span class="kw">summarize</span>(
      <span class="dt">diff_mean =</span> <span class="kw">mean</span>(bt_diff),
      <span class="dt">diff_sd =</span> <span class="kw">sd</span>(bt_diff),
      <span class="dt">p_val =</span> <span class="kw">sum</span>(bt_diff<span class="op">&gt;</span><span class="dv">0</span>)<span class="op">/</span><span class="kw">length</span>(bt_diff)<span class="op">*</span><span class="dv">2</span>, 
      <span class="dt">theory_mean =</span> pop_diff, 
      <span class="dt">theory_sd =</span> pop_sigma<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(bt_diff)),
      <span class="dt">abs_error_mean =</span> <span class="kw">abs</span>(diff_mean <span class="op">-</span><span class="st"> </span>theory_mean),
      <span class="dt">abs_error_sd =</span> <span class="kw">abs</span>(diff_sd <span class="op">-</span><span class="st"> </span>theory_sd)
    )
}</code></pre></div>
<ol start="8" style="list-style-type: lower-alpha">
<li><p>Review the above functions to understand each line. Use <code>?function_name</code> for look-up. Observe how <code>p_val</code> in <code>stats_sample_movies()</code> relates to the area of the density generated by <code>density_sample_movies()</code>. Also, check what theoretical sd in <code>stats_sample_movies()</code> calculates (for example, sd of what?).</p></li>
<li><p>Change N and B several times to observe how they influence the results.</p></li>
</ol>
</div>
<div id="part-b-analyze-the-performance-of-clt" class="section level4 unnumbered">
<h4>Part B: Analyze the performance of CLT</h4>
<ol style="list-style-type: lower-alpha">
<li><p>Pick 6 values between 0 and 120 for the number of observations <code>N</code> and store them as a vector named <code>loc_N</code>: i.e., <code>loc_N &lt;- c(20, 30, ...)</code>. Pick 5 values between 100 and 5000 for the number of bootstrap replications <code>B</code> and store them as a vector named <code>loc_B</code>.</p></li>
<li><p>Conduct 30 simulations of bootstrapping for each combination of <code>N</code> and <code>B</code> from <code>loc_N</code> and <code>loc_B</code> and store the results of density plots and summary stats in nested lists using the following code (simply copy and execute the code, note: function <code>my_movie_samples()</code> is from item e of part A);</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">list_density &lt;-<span class="st"> </span><span class="kw">list</span>()
list_stats &lt;-<span class="st"> </span><span class="kw">list</span>()

<span class="co"># This will take some time</span>
<span class="cf">for</span> (idx_N <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(loc_N)) { 
  list_density[[idx_N]] &lt;-<span class="st"> </span><span class="kw">list</span>()
  list_stats[[idx_N]] &lt;-<span class="st"> </span><span class="kw">list</span>()
  <span class="cf">for</span> (idx_B <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(loc_B)) {
    <span class="kw">print</span>(<span class="kw">paste0</span>(<span class="st">&#39;N =&#39;</span>, loc_N[idx_N],<span class="st">&#39;, B = &#39;</span>, loc_B[idx_B]))
    my_boot1 &lt;-<span class="st"> </span>mosaic<span class="op">::</span><span class="kw">do</span>(loc_B[idx_B]) <span class="op">*</span><span class="st"> </span>{
      <span class="kw">my_movie_samples</span>(loc_N[idx_N]) 
    }
    reshaped_my_boot1 &lt;-<span class="st"> </span><span class="kw">reshape_movie_samples</span>(my_boot1)
    list_density[[idx_N]][[idx_B]] &lt;-<span class="st"> </span><span class="kw">density_sample_movies</span>(reshaped_my_boot1,
                                                            loc_N[idx_N], loc_B[idx_B])
    list_stats[[idx_N]][[idx_B]]  &lt;-<span class="st"> </span><span class="kw">stats_sample_movies</span>(reshaped_my_boot1)
  }
}</code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Print the density plots and observe how they vary with <span class="math inline">\(N\)</span> (simply copy and execute the code). Do this for the largest <span class="math inline">\(B\)</span> first, then the smallest <span class="math inline">\(B\)</span>. You can use the following code and use the arrows (<code>&lt;-</code>, <code>-&gt;</code>) in the Plots Pane of Rstudio. How would you characterize the results?</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Use Plots Pane in RStudio  &lt;- -&gt; to observe the influence of N  </span>
<span class="cf">for</span> (idx_N <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(loc_N)) <span class="kw">print</span>(list_density[[idx_N]][[<span class="kw">which</span>(loc_B<span class="op">==</span><span class="kw">max</span>(loc_B))]])

<span class="co"># dispersion decreases with N</span>
<span class="cf">for</span> (idx_N <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(loc_N)) <span class="kw">print</span>(list_density[[idx_N]][[<span class="kw">which</span>(loc_B<span class="op">==</span><span class="kw">min</span>(loc_B))]]) </code></pre></div>
<ol start="4" style="list-style-type: lower-alpha">
<li>Use the following code to extract the results from the nested lists.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">extract_list_stats_N &lt;-<span class="st"> </span><span class="cf">function</span>(seq, idx_B, stat) {
  <span class="kw">lapply</span>(<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(seq)), 
         <span class="cf">function</span> (idx_N) list_stats[[idx_N]][[idx_B]][[stat]]) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()
}

extract_list_stats_B &lt;-<span class="st"> </span><span class="cf">function</span>(seq, idx_N, stat) {
  <span class="kw">lapply</span>(<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(seq)), 
         <span class="cf">function</span> (idx_B) list_stats[[idx_N]][[idx_B]][[stat]]) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()
}

max_B &lt;-<span class="st"> </span><span class="kw">which</span>(loc_B<span class="op">==</span><span class="kw">max</span>(loc_B)) <span class="co"># index of max B</span>
max_N &lt;-<span class="st"> </span><span class="kw">which</span>(loc_N<span class="op">==</span><span class="kw">max</span>(loc_N)) <span class="co"># index of max N</span>

results_N &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">N =</span> loc_N,
  <span class="dt">p_val =</span>  <span class="kw">extract_list_stats_N</span>(loc_N, max_B, <span class="st">&quot;p_val&quot;</span>),
  <span class="dt">abs_error_mean =</span>  <span class="kw">extract_list_stats_N</span>(loc_N, max_B, <span class="st">&quot;abs_error_mean&quot;</span>),
  <span class="dt">abs_error_sd  =</span>  <span class="kw">extract_list_stats_N</span>(loc_N, max_B, <span class="st">&quot;abs_error_sd&quot;</span>)
  )

results_B &lt;-<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">B =</span> loc_B,
  <span class="dt">p_val =</span>  <span class="kw">extract_list_stats_B</span>(loc_B, max_N, <span class="st">&quot;p_val&quot;</span>),
  <span class="dt">abs_error_mean =</span> <span class="kw">extract_list_stats_B</span>(loc_B, max_N, <span class="st">&quot;abs_error_mean&quot;</span>),
  <span class="dt">abs_error_sd  =</span>  <span class="kw">extract_list_stats_B</span>(loc_B, max_N, <span class="st">&quot;abs_error_sd&quot;</span>)
)</code></pre></div>
<ol start="5" style="list-style-type: lower-alpha">
<li><p>Use <code>ggplot()</code> on <code>results_N</code> to characterize the relationships between sample size <code>N</code> and <code>p_val</code>, between <code>N</code> and <code>abs_error_mean</code>, and between <code>N</code> and <code>abs_error_sd</code>. Which relationship shows a clear pattern? Why? Hint: use <code>geom_point()</code> and <code>geom_smooth()</code>. How does this relate to the CLT?</p></li>
<li><p>Use <code>ggplot()</code> on <code>results_B</code> to characterize the relationships between bootstrap size <code>B</code> and <code>p_val</code>, between <code>B</code> and <code>abs_error_mean</code>, and between <code>B</code> and <code>abs_error_sd</code>. Which relationship shows a clear pattern? Why?</p></li>
</ol>
</div>
<div id="part-c-analyze-data-with-linear-models" class="section level4 unnumbered">
<h4>Part C: Analyze data with linear models</h4>
<p>You will analyze <code>ChickWeight</code> data that is a part of the sample datasets automatically loaded when you start R. You will run linear models and get some practice on fixed effects (FE) and random effects (RE) models.</p>
<p>The <code>ChickWeight</code> dataset contains data of a diet experiment on early growth of chicks. There are four variables: weight (gm), Time (days), Chick (id), and Diet (1 through 4 types). Run the following code to observe the basic structure of the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">?ChickWeight <span class="co"># description shows up in the Help pane</span>
ChickWeight2 &lt;-<span class="st"> </span>ChickWeight  <span class="co"># make a copy that we may modify </span>
<span class="kw">head</span>(ChickWeight2)

<span class="kw">table</span>(ChickWeight2<span class="op">$</span>Chick)
<span class="kw">table</span>(ChickWeight2<span class="op">$</span>Diet)
<span class="kw">table</span>(ChickWeight2<span class="op">$</span>Chick, ChickWeight2<span class="op">$</span>Diet)

ChickWeight2 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Time, <span class="dt">y =</span> weight, <span class="dt">color =</span> Diet)) <span class="op">+</span><span class="st"> </span>
<span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">size =</span> .<span class="dv">25</span>, <span class="dt">alpha=</span>.<span class="dv">5</span>) <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>Chick)</code></pre></div>
<p>How would you go about analyzing the effect of Diets on weight growth?</p>
<p>Let <span class="math inline">\(weight_{ijt}\)</span> be the weight of chick <span class="math inline">\(i\)</span> in Diet group <span class="math inline">\(j\)</span> observed in time <span class="math inline">\(t\)</span>. You will run the following linear models with <code>lm()</code>, see the summary via <code>summary()</code>, and interpret the effects of four Diet types.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Let’ start with a model of diet-specific intercepts and a quadratic time trend given by <span class="math display">\[ weight_{ijt} = \alpha_j + \beta_1\: time_t + \beta_2 \: time^2_t + \varepsilon_{ijt}. \]</span> Hint: Use <code>I(Time^2)</code> in the formula.</p></li>
<li><p>Next try a fixed effect (FE) model given by <span class="math display">\[ weight_{ijt} = \alpha_j + \beta_1\: time_t + \beta_2 \: time^2_t + \alpha_i + \varepsilon_{ijt} \]</span> where <span class="math inline">\(\alpha_i\)</span> is a fixed effect representing a fixed intercept for each Chick. You may be surprised by the result.</p></li>
<li><p>Next try a random-effect (RE) model given by <span class="math display">\[ weight_{ijt} = \alpha_j + \beta_1\: time_t + \beta_2 \: time^2_t + v_{it}, \quad  v_{it} = \alpha_i + \varepsilon_{ijt}\]</span> where <span class="math inline">\(\alpha_i\)</span> is a random effect representing a random intercept for each Chick assumed to be normally distributed. Use <code>lmer()</code> from <code>lme4</code> package instead of <code>lm()</code> and replace variable <code>Chick</code> with random intercept <code>(1 | Chick)</code> in the formula.</p></li>
</ol>
<p>You probably observed that some of the above models yield very different results. Why?</p>
<p>Are <em>some</em> of these models wrong? In fact, it could be that <em>all</em> of them are wrong.</p>
<p>In the experiment, Diet types are probably randomly assigned across Chicks, and in that sense there is no obvious source of bias in the linear model construction. Thus, you should get similar results across models if your <em>modeling approach</em> is on the right track. Now go back to the initial plot of weight growth by chick and think of how else you could approach the problem.</p>
<p>Did it occur to you that <strong>the weight probably started out about the same across Diet groups and then took different paths given the Diet type</strong>?</p>
<ol start="4" style="list-style-type: lower-alpha">
<li><p>Let’s try varying linear time trends with the shared initial average weight at <span class="math inline">\(Time_t=0\)</span>.<br />
<span class="math display">\[ weight_{ijt} = \alpha_{0} + \beta_{1j}\: time_t + \varepsilon_{ijt}\]</span> where <span class="math inline">\(\beta_{1j}\)</span> is a (fixed) Diet-specific linear time trend. Hint: use <code>Diet*Time</code> and <code>-Diet</code> in the formula to create the interaction terms between <code>Time</code> and <code>Diet</code> and suppress the fixed intercept of <code>Diet</code>.</p></li>
<li><p>Now try <span class="math display">\[ weight_{ijt} = \alpha_{0} + \beta_{1j}\: time_t + \alpha_i + \varepsilon_{ijt}\]</span></p></li>
</ol>
<p>where <span class="math inline">\(\alpha_i\)</span> is a Chick fixed effect.</p>
<ol start="6" style="list-style-type: lower-alpha">
<li>Now try <span class="math display">\[ weight_{ijt} = \alpha_{0} + \beta_{1j}\: time_t + v_{ijt}, \quad v_{ijt} =\alpha_i + \varepsilon_{ijt}\]</span></li>
</ol>
<p>where <span class="math inline">\(\alpha_i\)</span> is a Chick random effect.</p>
<p>This time you should get pretty similar results across models in d, e, and f. How would you interpret the coefficient <span class="math inline">\(\beta_{1j}\)</span> of interaction terms between <code>Time</code> and <code>Diet</code>?</p>
<ol start="7" style="list-style-type: lower-alpha">
<li><p>Let’s visualize what’s going on. Try <code>ggplot(aes(x=..., y=..., color=...)) + geom_jitter() + geom_smooth()</code> to produce a scatter plot with smooth fitted curves by Diet types. Then, replace <code>geom_smooth()</code> with <code>geom_smooth(method = &quot;lm&quot;, formula = y ~ x)</code> for linear fit, followed by <code>geom_smooth(method = &quot;lm&quot;, formula = y ~  x + I(x^2))</code> for quadratic fit. Do the plots make intuitive sense?</p></li>
<li><p>Now try Diet-specific quadratic time trends;<br />
<span class="math display">\[ weight_{ijt} = \alpha_{0} + \beta_{1j}\: time_t + \beta_{2j} \: time^2_t + \varepsilon_{ijt}\]</span> where <span class="math inline">\(\alpha_0\)</span> is the common intercept across Diets. We may again suppress Diet-specific intercepts (using <code>-Diet</code>) by assuming that the average weight was the same across Diet groups at <span class="math inline">\(Time = 0\)</span>. Repeat this for the fixed effect and random effect models. How would you interpret the coefficient estimates on those quadratic time trends?</p></li>
<li><p>To visualize the results from h in a stylistic manner, we will replace the data points with the 25th, 50th, and 75th percentiles of weight for each Diet and Time. Then, overlay the results from h on this plot. Hint: add variables to <code>ChickWeight2</code> via <code>group_by(Diet, Time)</code> and <code>mutate(varname = quantile(...))</code>. Create a new <code>ggplot(aes(x=..., y=..., ymin=..., ymax=..., color=...))</code> with <code>geom_point(position = position_dodge(width = 1))</code> (adding points with <code>y</code> variable) and <code>geom_linerange(position = position_dodge(width = 1)</code> (adding vertical bars for 25th to 75th range with <code>ymin</code> and <code>ymax</code> variables). To overlay a regression result, use <code>prev_data_plot + geom_smooth(aes( x = ..., y = predict(reg_model_name), color=...), formula = ...)</code>.</p></li>
</ol>
</div>
</div>
<div id="the-key-1" class="section level3 unnumbered">
<h3>The Key</h3>
<p><a href="bootstrap/key_boot.nb.html">Click here</a></p>
</div>
<div id="reflections-2" class="section level3 unnumbered">
<h3>Reflections</h3>
<p>To be written.</p>
<p>If you are interested in bootstrapping random effects, <a href="bootstrap/RE_boot.nb.html">here is an example</a>.</p>

</div>
</div>
<div id="disqus_thread"></div>
<script>
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//piecemealr.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the
<a href="https://disqus.com/?ref_noscript">
  comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="4-1-dplyr.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="4-3-mixed.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": true,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/kotamine/piecemealR/edit/master/04-02-boot.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection",
"toc": true,
"toc_depth": 3,
"scroll_highlight": true
},
"code_folding": "show",
"highlight": "zenburn",
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
