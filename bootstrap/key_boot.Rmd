---
title: "Key: Random Sampling, Bootstrapping, and Linear Models"
output: html_notebook
---

Load libraries and data.

```{r, warning=FALSE, message=FALSE}
    library(dplyr)
    library(ggplot2)
    library(broom)
    library(tidyr)
    library(mosaic)
    library(nlme)
    library(lme4)
    library(knitr)
load("movies2.RData")
```


### Part A.  Part A: Observe the Central Limit Theorem (CLT) {-}

```{r}
pop_summary <- movies2 %>% group_by(genre) %>% 
  summarize(
    mean = mean(rating),
    sigma = sd(rating)) # call it sigma instead of sd 
pop_summary # answer to a.

pop_diff <- pop_summary$mean[1] - pop_summary$mean[2]  
pop_sigma <- sqrt(pop_summary$sigma[1]^2+ pop_summary$sigma[2]^2)
c(pop_diff, pop_sigma) # answer to b.
```

answer to c.: Normal distribution with mean `pop_diff` and standard deviation `pop_sigma/N` where `N` is a sample size. 

```{r}
set.seed(2007)

# answer to d. 
movies2 %>% group_by(genre) %>% 
  sample_n(30) %>% summarize(mean = mean(rating), sd = sd(rating),  n= n()) 
  
# answer to e. 
my_movie_samples  <- function(sample_size) {
  movies2 %>%  # test
    group_by(genre) %>% 
    sample_n(sample_size) %>%   #  don't get confused with sample()
      summarize( mean = mean(rating), 
                 sd = sd(rating), 
                 n = n())
}

# answer to f.                
my_boot1 <- mosaic::do(100) * {
  my_movie_samples(30) 
}

reshape_movie_samples <- function(bt_samples) {
  bt_samples %>% data.frame() %>%  # don't forget to use data.frame()
    dplyr::select(-.row) %>% 
    reshape(idvar= ".index", timevar="genre",
            direction="wide") %>%
    mutate(bt_diff  = (mean.Action - mean.Romance))  
}

reshaped_my_boot1 <- reshape_movie_samples(my_boot1)


density_sample_movies <- function(rehsaped_samples, N, B) {
  rehsaped_samples %>%
    ggplot(aes(x = bt_diff)) +
    geom_density(fill = "steelblue", adjust = 2, alpha = .75) + xlim(c(-2, 2) +  pop_diff) +
    geom_vline(xintercept = mean(rehsaped_samples$bt_diff), color = "steelblue", size = 1) +
    geom_vline(xintercept = pop_diff, color = "yellow", size = 1) + # CTL prediction mean
    stat_function(fun = dnorm, colour = "yellow", size =1, # CTL prediction distribution 
                  args = list(mean = pop_diff,
                              sd = pop_sigma/sqrt(rehsaped_samples$n.Action[1]))) +
     labs(title = paste0("Bootstrop: ", B, ",  Num observations:", N ))
}

stats_sample_movies <- function(reshaped_samples) {
  reshaped_samples %>%   
    summarize(
      diff_mean = mean(bt_diff),
      diff_sd = sd(bt_diff),
      p_val = sum(bt_diff>0)/length(bt_diff)*2, 
      theory_mean = pop_diff, 
      theory_sd = pop_sigma/sqrt(length(bt_diff)),
      abs_error_mean = abs(diff_mean - theory_mean),
      abs_error_sd = abs(diff_sd - theory_sd)
    )
}

# answer to g.
density_sample_movies(reshaped_my_boot1, 30, 100)
stats_sample_movies(reshaped_my_boot1)
```

#### Part B: Analyze the performance of CLT {-}

```{r}

loc_N <- c(20, 30, 40, 50, 75, 100)
loc_B <- c(100, 500, 1000, 2000, 4000)

# This will take some time
for (idx_N in 1:length(loc_N)) { 
  list_density[[idx_N]] <- list()
  list_stats[[idx_N]] <- list()
  for (idx_B in 1:length(loc_B)) {
    print(paste0('N =', loc_N[idx_N],', B = ', loc_B[idx_B]))
    my_boot1 <- mosaic::do(loc_B[idx_B]) * {
      my_movie_samples(loc_N[idx_N]) 
    }
    reshaped_my_boot1 <- reshape_movie_samples(my_boot1)
    list_density[[idx_N]][[idx_B]] <- density_sample_movies(reshaped_my_boot1, loc_N[idx_N], loc_B[idx_B])
    list_stats[[idx_N]][[idx_B]]  <- stats_sample_movies(reshaped_my_boot1)
  }
}

# Use Plot Pane in RStudio  <- -> to observe the influence of N  
for (idx_N in 1:length(loc_N)) print(list_density[[idx_N]][[which(loc_B==max(loc_B))]])

# dispersion decreases with N
for (idx_N in 1:length(loc_N)) print(list_density[[idx_N]][[which(loc_B==min(loc_B))]]) 


extract_list_stats_N <- function(seq, idx_B, stat) {
  lapply(c(1:length(seq)), 
         function (idx_N) list_stats[[idx_N]][[idx_B]][[stat]]) %>% unlist()
}

extract_list_stats_B <- function(seq, idx_N, stat) {
  lapply(c(1:length(seq)), 
         function (idx_B) list_stats[[idx_N]][[idx_B]][[stat]]) %>% unlist()
}

max_B <- which(loc_B==max(loc_B)) # index of max B
max_N <- which(loc_N==max(loc_N)) # index of max N

results_N <- data.frame(
  N = loc_N,
  p_val =  extract_list_stats_N(loc_N, max_B, "p_val"),
  abs_error_mean =  extract_list_stats_N(loc_N, max_B, "abs_error_mean"),
  abs_error_sd  =  extract_list_stats_N(loc_N, max_B, "abs_error_sd")
  )

results_B <- data.frame(
  B = loc_B,
  p_val =  extract_list_stats_B(loc_B, max_N, "p_val"),
  abs_error_mean = extract_list_stats_B(loc_B, max_N, "abs_error_mean"),
  abs_error_sd  =  extract_list_stats_B(loc_B, max_N, "abs_error_sd")
)

# answer to e.
results_N %>%  # proportional to 1/sqrt(N)
  ggplot(aes(x = N, y = p_val)) + geom_point() +
  geom_smooth(method = "lm", formula = y ~ sqrt(1/x), se=FALSE)

results_N %>% # already unbiased estimator (each mean gets more accurete with N but the mean of means do not)
  ggplot(aes(x = N, y =  abs_error_mean)) + geom_point()  +
  geom_smooth(method = "lm", formula = y ~ sqrt(1/x), se=FALSE)

results_N %>% # proportional to 1/sqrt(N)
  ggplot(aes(x = N, y =  abs_error_sd)) + geom_point()  +
  geom_smooth(method = "lm", formula = y ~ sqrt(1/x), se=FALSE)

# answer to f. 
#  slowly converges to some lower or upper bounds for given N, not really following 1/sqrt(N) function 
results_B %>%  
  ggplot(aes(x = B, y = p_val)) + geom_point() +
  geom_smooth(method = "lm", formula = y ~ sqrt(1/x), se=FALSE)

results_B %>%  
  ggplot(aes(x = B, y = abs_error_mean)) + geom_point() +
  geom_smooth(method = "lm", formula = y ~ sqrt(1/x), se=FALSE)

results_B %>%  
  ggplot(aes(x = B, y = abs_error_sd)) + geom_point() +
  geom_smooth(method = "lm", formula = y ~ sqrt(1/x), se=FALSE)

```


#### Part C: Analyze data with linear models  {-}

```{r}
# answers to a through d.  
lm( weight ~ Diet + Time + I(Time^2) , data = ChickWeight2) %>% summary()
lm( weight ~ Diet + Time + I(Time^2) + Chick, data = ChickWeight2) %>% summary()
lmer( weight ~ Diet + Time + I(Time^2) + (1 | Chick), data = ChickWeight2) %>% summary()
lmer( weight ~  (1 | Diet) + Time + I(Time^2) + (1 | Chick), data = ChickWeight2) %>% summary()
```

```{r}
# answers to e through g.
lm( weight ~ Diet*Time - Diet, data = ChickWeight2) %>% summary()
lm( weight ~ Diet*Time - Diet + Chick, data = ChickWeight2) %>% summary()
lmer( weight ~ Diet*Time - Diet + (1 | Chick), data = ChickWeight2) %>% summary()
```

```{r}
# answer to h.
lm( weight ~ Diet*Time + Diet*I(Time^2) - Diet, data = ChickWeight2) %>% summary()
lm( weight ~ Diet*Time + Diet*I(Time^2) - Diet + Chick, data = ChickWeight2) %>% summary()
lmer( weight ~ Diet*Time + Diet*I(Time^2) - Diet + (1 | Chick), data = ChickWeight2) %>% summary()

# answer to i.
lm( weight ~ Diet*Time + Diet*I(Time^2), data = ChickWeight2) %>% summary()
lm( weight ~ Diet*Time + Diet*I(Time^2) + Chick, data = ChickWeight2) %>% summary()
lmer( weight ~ Diet*Time + Diet*I(Time^2) + (1 | Chick), data = ChickWeight2) %>% summary()
```

```{r}
# answer to j.
# default smooth fit
ChickWeight2 %>% 
 ggplot(aes(x = Time, y = weight, color = Diet)) + 
 geom_jitter(size =.75, alpha=.5) + geom_smooth()

# linear fit
ChickWeight2 %>% 
 ggplot(aes(x = Time, y = weight, color = Diet)) + 
 geom_jitter(size =.75, alpha=.5) + geom_smooth(method = "lm", formula = y ~ x)

# quadratic fit
ChickWeight2 %>% 
 ggplot(aes(x = Time, y = weight, color = Diet)) + 
 geom_jitter(size =.75, alpha=.5) + geom_smooth(method = "lm", formula = y ~ x + I(x^2))
```


#### Part D Apply bootstrapping to linear models {-} 

```{r, echo=FALSE}
# answer to a. 

model_e <- lm( weight ~ Diet*Time - Diet, data = ChickWeight2) 
rlt_model_e_bt <- run_ols_boot(model_e, num_do = 2000)

obs_model_e <- tidy(model_e)  # summary of the original OLS estimates 

bt_sd_e <- apply(rlt_model_e_bt, 2, sd) # calculate bootstrap standard errors 
bt_mode1_e <- cbind(coeff = obs_model_e$estimate, 
                 sd = bt_sd_e, 
                 tstat = obs_model_e$estimate/bt_sd_e) 

# OLS estimate with statistical inferences by statistic theory
obs_model_e

# OLS estimate with statistical inferences by bootstrapping
bt_mode1_e 
```


```{r} 

# function generating a matrix of ones 
ones <- function(r,c) matrix(c(rep(1,r*c)),nrow=r,ncol=c)

# confidence interval by bootstrapping
# version 1 
ci_ver1 <- function(est_bt, alpha = 0.05) {
  # est_bt: bootstrap estimates with  row = boot replications, col = coefficients 
  apply(est_bt, 2, function(x) quantile(x, c(alpha/2, 1 - alpha/2))) %>% t() 
}

# version 2 
ci_ver2 <- function(est_sample, bt_sd, alpha = 0.05) {
  # est_semple: sample estimate vector 
  # bt_sd: bootstrap sd estimates of est_sample-vector  
  cbind('2.5%' = est_sample - 1.96 * bt_sd, 
      '97.5%' = est_sample + 1.96 * bt_sd) 
}
  
# bootstrap p-value 
bt_p_val <- function(est_sample, est_bt) {
  # est_semple: sample estimate vector 
  # est_bt: bootstrap estimates with  row = boot replications, col = coefficients 
  
  est_bt_long <- est_bt %>% data.frame() %>% gather()  
  
  est_bt_long <- est_bt_long %>%
    mutate(
        center_var = kronecker(ones(nrow(est_bt),1), matrix(est_sample, nrow=1)) %>% c(),
        extremes = abs(value - center_var) >= abs(center_var)
    )
    
  p_val <- est_bt_long %>% 
    group_by(key) %>% 
    summarise(p_val = sum(extremes)/nrow(est_bt))
  return(list(p_val=p_val, df_long=est_bt_long))
}

ci_ver1(rlt_model_e_bt)
ci_ver2(obs_model_e$estimate, bt_sd_e, model_e$df.residual)
bt_p_val(obs_model_e$estimate, rlt_model_e_bt)$p_val 

# histogram visualization  
coeff_bt_histogram <- function(est_sample, est_bt, centering =FALSE) { 
  # est_semple: sample estimate vector 
  # est_bt: bootstrap estimates with  row = boot replications, col = coefficients 

  est_bt_long <- bt_p_val(est_sample, est_bt)$df_long
  
  if (centering) {
    est_bt_long <- est_bt_long %>%
      mutate(
          key = paste(key, " - center"),
          value = value - center_var,
          fill_var = extremes
      )
    legend_lab <- "Extremes: | value - center | > | center |"
    x_lab <- "value - center"
  } else {
    est_bt_long <- est_bt_long %>%
      mutate(
        sign = kronecker(ones(nrow(est_bt),1), matrix(ifelse(est_sample>0,1,-1), nrow=1)) %>% c(), 
        fill_var = value * sign <= 0
      )
    legend_lab <- "Crossing zero?"
    x_lab <- "value"
  }
  
  est_bt_long %>% 
    ggplot(aes(x = value, fill = fill_var)) +
    geom_histogram(color = "white", bins = 40) + theme(legend.position="top") +
    facet_wrap(~key, scales = "free") + labs(fill = legend_lab, x = x_lab)
}

coeff_bt_histogram(obs_model_e$estimate, rlt_model_e_bt, centering=FALSE)
```


```{r}
# answer to b. 
model_f <- lm( weight ~ Diet*Time - Diet + Chick, data = ChickWeight2) 
rlt_model_f_bt <- run_ols_boot(model_f, num_do = 2000)

obs_model_f <- tidy(model_f)  # summary of the original OLS estimates 

bt_sd_f <- apply(rlt_model_f_bt, 2, sd) # calculate bootstrap standard errors 
bt_mode1_f <- cbind(coeff = obs_model_f$estimate, 
                 sd = bt_sd_f, 
                 tstat = obs_model_f$estimate/bt_sd_f) 

# OLS estimate with statistical inferences by statistic theory
obs_model_f

# OLS estimate with statistical inferences by bootstrapping
bt_mode1_f

ci_ver1(rlt_model_f_bt)
ci_ver2(obs_model_f$estimate, bt_sd_f, model_f$df.residual)
bt_p_val(obs_model_f$estimate, rlt_model_f_bt)$p_val 

obs_model_f_time <- obs_model_f %>% filter(grepl("Intercept", term) | grepl("Time", term)) 
obs_model_f_chick <- obs_model_f %>% filter(grepl("Chick", term)) 
rlt_model_f_bt_time <- rlt_model_f_bt %>% dplyr::select(contains("Intercept"), contains("Time")) 
rlt_model_f_bt_chick <- rlt_model_f_bt %>% dplyr::select(contains("Chick")) 

coeff_bt_histogram(obs_model_f_time$estimate, rlt_model_f_bt_time, centering=FALSE)
coeff_bt_histogram(obs_model_f_chick$estimate[1:6], rlt_model_f_bt_chick[,1:6], centering=FALSE)
```


```{r}
getFormula <- function(ols, lmer=FALSE) gsub("()","", ifelse(!lmer, ols$call[2], ols@call[2])) 
getFormula(model_g, lmer=TRUE)

getDependentVar <- function(ols, lmer=FALSE) {
  str <- getFormula(ols, lmer=lmer) 
  gsub(" ","", substr(str, 1, (regexpr("~",str)[1]-1)))　 
  }
getDependentVar(model_g, lmer=TRUE)


run_lmer_boot <- function(lmer_rlt, num_do = 5000) {
  # Randome effects (RE) model bootstrapping (random intercepts, not random slopes) 
  
  rlt <- list()
  rlt$model <- model_g@pp$X        # model data for the part of fixed coefficients
  N <- length(residuals(lmer_rlt))
  
  rlt$fitted_no_RE <- rlt$model %*% matrix(fixef(lmer_rlt), ncol=1)
  RE_vals <- lmer_rlt@flist[[1]] %>% unique()  #  RE variable values
  N_RE <- length(RE_vals)                 # number of RE variable values
  rlt$RE_idx <- rep(NA, N)
  for (i in 1:N_RE) rlt$RE_idx[which(lmer_rlt@flist[[1]] == RE_vals[i])] <- i  # index of RE variable values
 
  sd_res <-  sigma(lmer_rlt)        # standard deviation of the residuals
  sd_RE <-  lmer_rlt@theta * sd_res   # standard deviation of RE
  dep_var <- getDependentVar(lmer_rlt, lmer=TRUE) 

  do(num_do) * 
    ({  
        data_bt <- data.frame(lmer_rlt@frame)
    
        # replace the dependent variable with its bootstrap counterpart
        data_bt[[dep_var]] <- rlt$fitted_no_RE +          # the predicted component by fixed coefficients 
          + rnorm(N_RE, mean = 0, sd = sd_RE)[rlt$RE_idx] + # random draws of tge RE distribution
          + rnorm(N, mean = 0, sd = sd_res)               # random draws of the residual distribution
         
        # run the RE model with the same formula but with a new, bootstrap dataset  
        lmer_bt <- lmer(as.formula(getFormula(lmer_rlt, lmer=TRUE)), data = data_bt)  
        sd_res_bt <-  sigma(lmer_bt)  
        sd_RE_bt <-  lmer_bt@theta * sd_res_bt
        c(fixef(lmer_bt), sigma_RE = sd_RE_bt, sigma_res = sd_res_bt)  # get fixed coefficients 
    }) 
}
```

```{r}
# answer to c. 

model_g <- lmer( weight ~ Diet*Time - Diet + (1 | Chick), data = ChickWeight2) 
rlt_model_g_bt <- run_lmer_boot(model_g, num_do = 2000)

obs_model_g <- tidy(model_g)  # summary of the original OLS estimates 

bt_sd_g <- apply(rlt_model_g_bt, 2, sd) # calculate bootstrap standard errors 
bt_mode1_g <- cbind(coeff = obs_model_g$estimate, 
                 sd = bt_sd_g, 
                 tstat = obs_model_g$estimate/bt_sd_g) 
 
# OLS estimate with statistical inferences by statistic theory
obs_model_g

# OLS estimate with statistical inferences by bootstrapping
bt_mode1_g

ci_ver1(rlt_model_g_bt)
ci_ver2(obs_model_g$estimate, bt_sd_g, (nrow(ChickWeight2) - nrow(obs_model_g)))
bt_p_val(obs_model_g$estimate, rlt_model_g_bt)$p_val 
coeff_bt_histogram(obs_model_g$estimate, rlt_model_g_bt, centering=FALSE)

```

